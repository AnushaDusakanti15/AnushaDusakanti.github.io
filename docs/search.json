[
  {
    "objectID": "quali.html",
    "href": "quali.html",
    "title": "EDUCATION",
    "section": "",
    "text": "I have completed my education from the below institutions:\n\nB.Tech in Computer Science and Engineering from MLR Institute of Technology, with 7.4 CGPA, in 2022\n12th grade from Narayana Junior College, with 94.2%, in 2018\n10th grade from Silver Oaks International School, with 9.8 CGPA, in 2016.\n\nGo back to home."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "WORK EXPERIENCE",
    "section": "",
    "text": "I completed an internship with Virtusa Consulting Services Pvt Ltd for 4 months.\nI worked as an Associate Engineer at Virtusa Consulting Services Pvt Ltd for 1.6 years.\n\nDuring this whole tenure at Virtusa, I was able to learn about AWS services and worked on a project and on a POC.\n\nPOC\nPeriod: October 2023 – December 2023\nRole: Developer\nI worked on a POC, which requires extraction of data from the source database using SQL and converting existing Java code to python code and migrating that data into AWS cloud.\nBMO – Digital Core B2B – TIBCO BW to AWS\nPeriod: January 2023 – September 2023\nRole: Developer\nMigrating TIBCO on-premises API from on-premises servers to AWS Cloud Environment. This migration requires understanding the business logic and creating the request and response structure of the API from the TIBCO Designer and understanding the design given by the AWS architect.\n\nGo back to home."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANUSHA DUSAKANTI",
    "section": "",
    "text": "Hello, I am Anusha Dusakanti and welcome to my website.\nI am currently pursuing my Masters in Data Analytics Engineering at George Mason University.\nMy passion to learn about data and its applications, made me choose this course for my Masters. I am confident that my proficiency in Java, Python, AWS will aid me in completing this course and I am looking forward to learn about R and using it for data visualizations.\nTo check out my projects of the course STAT515, please navigate to MidProject and FinalProject.\nTo see my final project report of AIT580 course, please click here."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "ANUSHA DUSAKANTI",
    "section": "",
    "text": "Hello, I am Anusha Dusakanti and welcome to my website.\nI am currently pursuing my Masters in Data Analytics Engineering at George Mason University.\nMy passion to learn about data and its applications, made me choose this course for my Masters. I am confident that my proficiency in Java, Python, AWS will aid me in completing this course and I am looking forward to learn about R and using it for data visualizations.\nTo check out my projects of the course STAT515, please navigate to MidProject and FinalProject.\nTo see my final project report of AIT580 course, please click here."
  },
  {
    "objectID": "Redesign.html",
    "href": "Redesign.html",
    "title": "STAT515 MID PROJECT",
    "section": "",
    "text": "Group 19:\n\n\nAnusha Dusakanti\n\n\nSumrah Shakeel\nBelow is a redesigning project on which my classmate, Sumrah Shakeel and I worked on for the Applied Statistics & Visualization for Analytics (STAT515) class taken at George Mason University. This project involves us finding a bad graph and redesigning it to display meaningful visualizations.\nThe graph we selected to redesign is a line chart that shows the Unemployment Rate from 1968-2022 in Japan. The amount of information on this graph is quite a lot and the viewer can barely pinpoint the percentages mentioned here.\n\n\n\nStrengths: Easy to Identify Trends\n\n\nWeakness: Cluttered, Overwhelming to the User, Difficult to Understand\n\n\nVisualization 1: Grouped Bar Chart for Youth Unemployment Rate during Employment Ice Age (1993-2004) in Japan\nWe redesigned the above graph as a bar chart, by considering the unemployment rate of youth(ages 15-24) during the Employment Ice Age period.\nFrom the graph below it is evident that the unemployment rate has steadily increased during the Employment Ice Age period. For all the person, it peaked in 2003 at 10.16%, for men it peaked in 2003 at 11.56%, and for women it peaked in 2001 at 8.71%. In 1994, which was the beginning of the Ice Age, the unemployment rate was the lowest for all people, men and women.\n\nStrengths: Easy to Compare Different Variables; Easy to Interpret\n\n\nWeakness: Difficult to Display Multiple Variables; Cannot Display Large Data on the x-axis\n\n\n\n\n\n\n\n\n\nVisualization 2: Multi-line plot of different genders, during the Employment Ice Age (1993-2004) in Japan\nOur next redesign is a multi-line plot with facets, with each facet representing a different gender and each line representing a trend during Japan’s Employment Ice Age (1993-2004). It is easy to see that the men’s unemployment rate has steadily increased until 2003, whilst the women’s unemployement rate has had short periods of decline.\n\nStrengths: Clearly distinguish between different genders; It displays trends over the years; It’s interactive\n\n\nWeakness: Line overlap caused by too many data points per category may hide patterns, making it difficult to detect distinct trends.\n\n\n\n\n\n\n\n\n\nVisualization 3: Line Chart showing Relationship between GDP Growth Rate and Youth Unemployment Rate in Japan\nFrom the line chart below, it looks like the Gross Domestic Product (GDP) growth rate has slowed down over years and the negative percentage indicates the recession that Japan was hit with. Unemployment rate was initially under 5% until the early 1990s and the then it started increasing and eventually peaked in 2003 reaching almost 10.16%. After this the unemployment rate started decreasing at a steady rate.\n\nStrengths: Easy to understand trends; Easy to correlate\n\n\nWeakness: Too much information can be overwhelming; Outliers can skew the data\n\n\n\n\n\n\n\n\n\nVisualization 4: World map with Youth Unemployment Rate of different countries in 2022\nThis last visualization depicts a world map showing the unemployment rates of various countries in 2022. We ranked the countries according to their unemployment rates and plotted them on a world map. The color legend ranges from red (Japan) representing the highest rated country to yellow (Greece), representing the lowest rated country.\n\nStrengths: Easy to identify the countries; Easy to compare rankings\n\n\nWeakness: Trends for specific countries cannot be shown.\n\n\n\n\n\n\nThe video below includes Sumrah and I walking you through the designing process of selecting a bad graph and then redesigning it into 4 different meaningful and interactive visualizations.\n\n\n\n\n\n\n\n\nReferences:\nOecd. (n.d.). LFS by sex and age - indicators. Organisation for Economic Co-operation and Development. https://stats.oecd.org/Index.aspx?DataSetCode=LFS_SEXAGE_I_R#\nOshio, T. (2020, September 5). Lingering Impact of Starting Working Life During a Recession: Health Outcomes of Survivors of the “Employment Ice Age” (1993–2004) in Japan. Journal of Epidemiology. https://doi.org/10.2188/jea.JE20190121\nUnemployment rate in Japan. Wikimedia Commons. (n.d.-a). https://commons.wikimedia.org/wiki/File:Unemployment_rate_in_Japan.svg\nWorld Development Indicators. The World Bank. (n.d.). https://databank.worldbank.org/reports.aspx?source=2&series=NY.GDP.MKTP.KD.ZG&country=JPN#advancedDownloadOptions"
  },
  {
    "objectID": "Midproject.html",
    "href": "Midproject.html",
    "title": "MIDPROJECT CODE",
    "section": "",
    "text": "Importing the CSV File containing Raw Data of Unemployment Rate alone\n\nlfs_sexage_raw = read.csv(\"/Users/anushadusakanti/Documents/GitHub/AnushaDusakanti15.github.io/LFS_SEXAGE_I_R_05032024021852784.csv\")\n\nUnderstanding the structure of the data frame\n\nstr(lfs_sexage_raw)\n\n'data.frame':   312384 obs. of  15 variables:\n $ COUNTRY   : chr  \"AUS\" \"AUS\" \"AUS\" \"AUS\" ...\n $ Country   : chr  \"Australia\" \"Australia\" \"Australia\" \"Australia\" ...\n $ SEX       : chr  \"MW\" \"MW\" \"MW\" \"MW\" ...\n $ Sex       : chr  \"All persons\" \"All persons\" \"All persons\" \"All persons\" ...\n $ AGE       : int  1519 1519 1519 1519 1519 1519 1519 1519 1519 1519 ...\n $ Age       : chr  \"15 to 19\" \"15 to 19\" \"15 to 19\" \"15 to 19\" ...\n $ SERIES    : chr  \"EPR\" \"EPR\" \"EPR\" \"EPR\" ...\n $ Series    : chr  \"Employment/population ratio\" \"Employment/population ratio\" \"Employment/population ratio\" \"Employment/population ratio\" ...\n $ FREQUENCY : chr  \"A\" \"A\" \"A\" \"A\" ...\n $ Frequency : chr  \"Annual\" \"Annual\" \"Annual\" \"Annual\" ...\n $ TIME      : int  1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 ...\n $ Time      : int  1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 ...\n $ Value     : num  58.5 56.7 57.2 55 54.1 ...\n $ Flag.Codes: logi  NA NA NA NA NA NA ...\n $ Flags     : logi  NA NA NA NA NA NA ...\n\n\nSub-setting the raw data to select Unemployment Rate data of Japanese Youth\n\nunemployment_rate_japan = subset(lfs_sexage_raw, Country == 'Japan' & Age == '15 to 24' & Series == 'Unemployment rate')\n\nunemployment_rate_japan\n\n      COUNTRY Country   SEX         Sex  AGE      Age SERIES            Series\n19496     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19497     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19498     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19499     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19500     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19501     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19502     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19503     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19504     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19505     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19506     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19507     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19508     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19509     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19510     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19511     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19512     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19513     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19514     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19515     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19516     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19517     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19518     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19519     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19520     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19521     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19522     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19523     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19524     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19525     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19526     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19527     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19528     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19529     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19530     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19531     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19532     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19533     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19534     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19535     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19536     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19537     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19538     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19539     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19540     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19541     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19542     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19543     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19544     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19545     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19546     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19547     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19548     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19549     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19550     JPN   Japan    MW All persons 1524 15 to 24     UR Unemployment rate\n19551     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19552     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19553     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19554     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19555     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19556     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19557     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19558     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19559     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19560     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19561     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19562     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19563     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19564     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19565     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19566     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19567     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19568     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19569     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19570     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19571     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19572     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19573     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19574     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19575     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19576     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19577     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19578     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19579     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19580     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19581     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19582     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19583     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19584     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19585     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19586     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19587     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19588     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19589     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19590     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19591     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19592     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19593     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19594     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19595     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19596     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19597     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19598     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19599     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19600     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19601     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19602     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19603     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19604     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19605     JPN   Japan   MEN         Men 1524 15 to 24     UR Unemployment rate\n19606     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19607     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19608     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19609     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19610     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19611     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19612     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19613     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19614     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19615     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19616     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19617     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19618     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19619     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19620     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19621     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19622     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19623     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19624     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19625     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19626     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19627     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19628     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19629     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19630     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19631     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19632     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19633     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19634     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19635     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19636     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19637     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19638     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19639     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19640     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19641     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19642     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19643     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19644     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19645     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19646     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19647     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19648     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19649     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19650     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19651     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19652     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19653     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19654     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19655     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19656     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19657     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19658     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19659     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n19660     JPN   Japan WOMEN       Women 1524 15 to 24     UR Unemployment rate\n      FREQUENCY Frequency TIME Time     Value Flag.Codes Flags\n19496         A    Annual 1968 1968  1.875000         NA    NA\n19497         A    Annual 1969 1969  1.828154         NA    NA\n19498         A    Annual 1970 1970  1.983769         NA    NA\n19499         A    Annual 1971 1971  2.129547         NA    NA\n19500         A    Annual 1972 1972  2.390057         NA    NA\n19501         A    Annual 1973 1973  2.344546         NA    NA\n19502         A    Annual 1974 1974  2.474691         NA    NA\n19503         A    Annual 1975 1975  3.048780         NA    NA\n19504         A    Annual 1976 1976  3.129074         NA    NA\n19505         A    Annual 1977 1977  3.537415         NA    NA\n19506         A    Annual 1978 1978  3.755216         NA    NA\n19507         A    Annual 1979 1979  3.394625         NA    NA\n19508         A    Annual 1980 1980  3.576538         NA    NA\n19509         A    Annual 1981 1981  4.011461         NA    NA\n19510         A    Annual 1982 1982  3.917379         NA    NA\n19511         A    Annual 1983 1983  4.526749         NA    NA\n19512         A    Annual 1984 1984  4.904632         NA    NA\n19513         A    Annual 1985 1985  4.774898         NA    NA\n19514         A    Annual 1986 1986  5.165563         NA    NA\n19515         A    Annual 1987 1987  5.235602         NA    NA\n19516         A    Annual 1988 1988  4.853129         NA    NA\n19517         A    Annual 1989 1989  4.455446         NA    NA\n19518         A    Annual 1990 1990  4.316547         NA    NA\n19519         A    Annual 1991 1991  4.462243         NA    NA\n19520         A    Annual 1992 1992  4.357542         NA    NA\n19521         A    Annual 1993 1993  5.105438         NA    NA\n19522         A    Annual 1994 1994  5.450501         NA    NA\n19523         A    Annual 1995 1995  6.094808         NA    NA\n19524         A    Annual 1996 1996  6.727480         NA    NA\n19525         A    Annual 1997 1997  6.643357         NA    NA\n19526         A    Annual 1998 1998  7.720145         NA    NA\n19527         A    Annual 1999 1999  9.275731         NA    NA\n19528         A    Annual 2000 2000  9.198423         NA    NA\n19529         A    Annual 2001 2001  9.712722         NA    NA\n19530         A    Annual 2002 2002 10.043042         NA    NA\n19531         A    Annual 2003 2003 10.164425         NA    NA\n19532         A    Annual 2004 2004  9.472050         NA    NA\n19533         A    Annual 2005 2005  8.647799         NA    NA\n19534         A    Annual 2006 2006  8.000000         NA    NA\n19535         A    Annual 2007 2007  7.704918         NA    NA\n19536         A    Annual 2008 2008  7.239057         NA    NA\n19537         A    Annual 2009 2009  9.075044         NA    NA\n19538         A    Annual 2010 2010  9.222423         NA    NA\n19539         A    Annual 2011 2011  8.023483         NA    NA\n19540         A    Annual 2012 2012  7.945736         NA    NA\n19541         A    Annual 2013 2013  6.883365         NA    NA\n19542         A    Annual 2014 2014  6.285714         NA    NA\n19543         A    Annual 2015 2015  5.523810         NA    NA\n19544         A    Annual 2016 2016  5.118830         NA    NA\n19545         A    Annual 2017 2017  4.595588         NA    NA\n19546         A    Annual 2018 2018  3.760684         NA    NA\n19547         A    Annual 2019 2019  3.660566         NA    NA\n19548         A    Annual 2020 2020  4.576271         NA    NA\n19549         A    Annual 2021 2021  4.623288         NA    NA\n19550         A    Annual 2022 2022  4.203152         NA    NA\n19551         A    Annual 1968 1968  1.867572         NA    NA\n19552         A    Annual 1969 1969  1.916376         NA    NA\n19553         A    Annual 1970 1970  2.061856         NA    NA\n19554         A    Annual 1971 1971  2.325581         NA    NA\n19555         A    Annual 1972 1972  2.669039         NA    NA\n19556         A    Annual 1973 1973  2.509653         NA    NA\n19557         A    Annual 1974 1974  2.736842         NA    NA\n19558         A    Annual 1975 1975  3.456221         NA    NA\n19559         A    Annual 1976 1976  3.448276         NA    NA\n19560         A    Annual 1977 1977  3.957784         NA    NA\n19561         A    Annual 1978 1978  4.359673         NA    NA\n19562         A    Annual 1979 1979  3.631285         NA    NA\n19563         A    Annual 1980 1980  3.977273         NA    NA\n19564         A    Annual 1981 1981  4.237288         NA    NA\n19565         A    Annual 1982 1982  4.201681         NA    NA\n19566         A    Annual 1983 1983  4.594595         NA    NA\n19567         A    Annual 1984 1984  4.851752         NA    NA\n19568         A    Annual 1985 1985  4.838710         NA    NA\n19569         A    Annual 1986 1986  5.235602         NA    NA\n19570         A    Annual 1987 1987  5.426357         NA    NA\n19571         A    Annual 1988 1988  5.050505         NA    NA\n19572         A    Annual 1989 1989  4.679803         NA    NA\n19573         A    Annual 1990 1990  4.513064         NA    NA\n19574         A    Annual 1991 1991  4.719101         NA    NA\n19575         A    Annual 1992 1992  4.575163         NA    NA\n19576         A    Annual 1993 1993  4.935622         NA    NA\n19577         A    Annual 1994 1994  5.591398         NA    NA\n19578         A    Annual 1995 1995  6.113537         NA    NA\n19579         A    Annual 1996 1996  6.798246         NA    NA\n19580         A    Annual 1997 1997  6.935123         NA    NA\n19581         A    Annual 1998 1998  8.158508         NA    NA\n19582         A    Annual 1999 1999 10.319410         NA    NA\n19583         A    Annual 2000 2000 10.432570         NA    NA\n19584         A    Annual 2001 2001 10.666667         NA    NA\n19585         A    Annual 2002 2002 11.325967         NA    NA\n19586         A    Annual 2003 2003 11.560694         NA    NA\n19587         A    Annual 2004 2004 10.638298         NA    NA\n19588         A    Annual 2005 2005  9.876543         NA    NA\n19589         A    Annual 2006 2006  8.805031         NA    NA\n19590         A    Annual 2007 2007  8.280255         NA    NA\n19591         A    Annual 2008 2008  7.894737         NA    NA\n19592         A    Annual 2009 2009 10.069444         NA    NA\n19593         A    Annual 2010 2010 10.431655         NA    NA\n19594         A    Annual 2011 2011  8.949416         NA    NA\n19595         A    Annual 2012 2012  8.745247         NA    NA\n19596         A    Annual 2013 2013  7.604563         NA    NA\n19597         A    Annual 2014 2014  7.116105         NA    NA\n19598         A    Annual 2015 2015  5.947955         NA    NA\n19599         A    Annual 2016 2016  5.714286         NA    NA\n19600         A    Annual 2017 2017  4.693141         NA    NA\n19601         A    Annual 2018 2018  4.054054         NA    NA\n19602         A    Annual 2019 2019  3.947368         NA    NA\n19603         A    Annual 2020 2020  5.000000         NA    NA\n19604         A    Annual 2021 2021  5.084746         NA    NA\n19605         A    Annual 2022 2022  4.878049         NA    NA\n19606         A    Annual 1968 1968  1.883239         NA    NA\n19607         A    Annual 1969 1969  1.730769         NA    NA\n19608         A    Annual 1970 1970  1.897533         NA    NA\n19609         A    Annual 1971 1971  1.904762         NA    NA\n19610         A    Annual 1972 1972  2.066116         NA    NA\n19611         A    Annual 1973 1973  2.159827         NA    NA\n19612         A    Annual 1974 1974  2.173913         NA    NA\n19613         A    Annual 1975 1975  2.590674         NA    NA\n19614         A    Annual 1976 1976  2.770083         NA    NA\n19615         A    Annual 1977 1977  3.089888         NA    NA\n19616         A    Annual 1978 1978  3.125000         NA    NA\n19617         A    Annual 1979 1979  3.151862         NA    NA\n19618         A    Annual 1980 1980  3.170029         NA    NA\n19619         A    Annual 1981 1981  3.779070         NA    NA\n19620         A    Annual 1982 1982  3.623188         NA    NA\n19621         A    Annual 1983 1983  4.456825         NA    NA\n19622         A    Annual 1984 1984  4.958678         NA    NA\n19623         A    Annual 1985 1985  4.709141         NA    NA\n19624         A    Annual 1986 1986  5.093834         NA    NA\n19625         A    Annual 1987 1987  5.039788         NA    NA\n19626         A    Annual 1988 1988  4.651163         NA    NA\n19627         A    Annual 1989 1989  4.228856         NA    NA\n19628         A    Annual 1990 1990  4.116223         NA    NA\n19629         A    Annual 1991 1991  4.195804         NA    NA\n19630         A    Annual 1992 1992  4.128440         NA    NA\n19631         A    Annual 1993 1993  5.287356         NA    NA\n19632         A    Annual 1994 1994  5.299539         NA    NA\n19633         A    Annual 1995 1995  6.074766         NA    NA\n19634         A    Annual 1996 1996  6.650831         NA    NA\n19635         A    Annual 1997 1997  6.326034         NA    NA\n19636         A    Annual 1998 1998  7.250000         NA    NA\n19637         A    Annual 1999 1999  8.157895         NA    NA\n19638         A    Annual 2000 2000  7.880435         NA    NA\n19639         A    Annual 2001 2001  8.707865         NA    NA\n19640         A    Annual 2002 2002  8.656716         NA    NA\n19641         A    Annual 2003 2003  8.668731         NA    NA\n19642         A    Annual 2004 2004  8.253968         NA    NA\n19643         A    Annual 2005 2005  7.371795         NA    NA\n19644         A    Annual 2006 2006  7.166124         NA    NA\n19645         A    Annual 2007 2007  7.094595         NA    NA\n19646         A    Annual 2008 2008  6.551724         NA    NA\n19647         A    Annual 2009 2009  8.070175         NA    NA\n19648         A    Annual 2010 2010  8.000000         NA    NA\n19649         A    Annual 2011 2011  7.086614         NA    NA\n19650         A    Annual 2012 2012  7.114625         NA    NA\n19651         A    Annual 2013 2013  6.153846         NA    NA\n19652         A    Annual 2014 2014  5.426357         NA    NA\n19653         A    Annual 2015 2015  5.078125         NA    NA\n19654         A    Annual 2016 2016  4.494382         NA    NA\n19655         A    Annual 2017 2017  4.494382         NA    NA\n19656         A    Annual 2018 2018  3.460208         NA    NA\n19657         A    Annual 2019 2019  3.367003         NA    NA\n19658         A    Annual 2020 2020  4.137931         NA    NA\n19659         A    Annual 2021 2021  4.152249         NA    NA\n19660         A    Annual 2022 2022  3.521127         NA    NA\n\n\nKeeping only the required columns, rounding the Unemployment Rate to 2 digits, renaming columns to appropriate names and resetting the row numbers\n\nsuppressMessages(library(dplyr))\nunemployment_rate_japan = select(unemployment_rate_japan, Sex, Time, Value)\nunemployment_rate_japan$Value = round(unemployment_rate_japan$Value, digits = 2)\nunemployment_rate_japan &lt;- unemployment_rate_japan %&gt;% \n  rename(Year = Time)\n\nrow.names(unemployment_rate_japan) = NULL\n\nSelecting only the Unemployment Ice Age Years and resetting the row numbers\n\ndata1993_2004 = subset(unemployment_rate_japan, Year &gt;= 1993 & Year  &lt;= 2004)\nrow.names(data1993_2004) = NULL\n\nTransposing the Unemployment Ice Age data by pivoting the table from long to wide.\n\nsuppressMessages(library(tidyr))\ntransposed_1993_2004 = pivot_wider(data1993_2004, names_from = \"Sex\", values_from = \"Value\")\n\nGrouping the transposed data by Year and renaming the column containing spaces in between\n\ngrouped_1993_2004 = transposed_1993_2004 %&gt;%\n  group_by(Year)\ngrouped_1993_2004 = grouped_1993_2004 %&gt;% \n  rename(All.persons = 'All persons')\n\nCreating an interactive bar plot with the manipulated data frame to portray the population during Unemployment Ice Age\n\nsuppressMessages(library(plotly))\n\nbar_plt_1993_2004 = plot_ly(grouped_1993_2004, x = ~Year, y = ~All.persons, type = 'bar', name = 'All persons',\n             marker = list(color = 'green')) %&gt;% \n    add_trace(y = ~Men, name = 'Men', \n              marker = list(color = 'blue')) %&gt;%\n    add_trace(y = ~Women, name = 'Women', \n              marker = list(color = 'red')) %&gt;%\n    layout(xaxis = list(title = \"Years\", tickmode='linear', tickangle = -90),\n           yaxis = list(title = \"Youth Unemployment Rate (%)\"),\n           title = 'Youth Unemployment Rate during Ice Age \\n Japan (1993-2004)',\n            barmode = 'group')\nbar_plt_1993_2004\n\n\n\n\n\nRedesigning the bar plot and creating a interactive line plot to portray the population with separate graphs during Unemployment Ice Age\n\nsuppressMessages(library(ggplot2))\nsuppressMessages(library(plotly))\ncc &lt;- c(\"green\",\"blue\", \"red\")\n\ngraph &lt;- ggplot(data1993_2004, aes(x = Year, y = Value, fill = Sex, group=1,\n                                  text = paste(\"Sex:\", Sex, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;UR:\", Value))) +\n  geom_line(color=\"black\") +\n  geom_point(shape = 21, size = 2.8) + \n  labs(x = \"Year\", y = \"Youth Unemployment Rate(%)\", title = \"Youth Unemployment Rate in Japan(1993-2004)\") +\n  facet_wrap(~ Sex) +\n  scale_fill_manual(values = cc) +\n  labs(fill = \"Population\") +\n  theme_grey() +\n  scale_x_continuous(breaks = seq(1993, 2004, by = 3))\n\nggplotly(graph, tooltip = \"text\")\n\n\n\n\n\nImporting the CSV file containing Japan’s Anual GDP Growth Rate obtained from https://databank.worldbank.org/reports.aspx?source=2&series=NY.GDP.MKTP.KD.ZG&country=JPN#advancedDownloadOptions\n\ngdp_annual_1960 = read.csv(\"/Users/anushadusakanti/Documents/GitHub/AnushaDusakanti15.github.io/Japan_GDP_Annual_Growth.csv\")\n\nUnderstanding the structure of the dataset\n\nstr(gdp_annual_1960)\n\n'data.frame':   72 obs. of  7 variables:\n $ Series.Name : chr  \"GDP growth (annual %)\" \"GDP growth (annual %)\" \"GDP growth (annual %)\" \"GDP growth (annual %)\" ...\n $ Series.Code : chr  \"NY.GDP.MKTP.KD.ZG\" \"NY.GDP.MKTP.KD.ZG\" \"NY.GDP.MKTP.KD.ZG\" \"NY.GDP.MKTP.KD.ZG\" ...\n $ Country.Name: chr  \"Japan\" \"Japan\" \"Japan\" \"Japan\" ...\n $ Country.Code: chr  \"JPN\" \"JPN\" \"JPN\" \"JPN\" ...\n $ Time        : chr  \"1960\" \"1961\" \"1962\" \"1963\" ...\n $ Time.Code   : chr  \"YR1960\" \"YR1961\" \"YR1962\" \"YR1963\" ...\n $ Value       : chr  \"..\" \"12.0435364080116\" \"8.90897299558067\" \"8.47364238279391\" ...\n\n\nSelecting only the columns required\n\ngdp_annual_1960 = select(gdp_annual_1960, Time, Value)\n\nKeeping only the meaningful rows\n\ngdp_annual = slice(gdp_annual_1960, 9:63)\n\nData Manipulation - converting character columns to numeric, rounding off percentage to 2 digits, and renaming columns appropriately\n\ngdp_annual$Time = as.numeric(gdp_annual$Time)\ngdp_annual$Value = as.numeric(gdp_annual$Value)\ngdp_annual$Value = round(gdp_annual$Value, digits = 2)\ngdp_annual = gdp_annual %&gt;% \n  rename(GDP_Annual_Growth = 'Value')\ngdp_annual = gdp_annual %&gt;% \n  rename(Year = 'Time')\n\nSubsetting the population to ‘All persons’ to get an overall unemployment outlook from the previously created Unemployment Rate data of Japanese Youth data frame\n\nunemployment_all_persons = subset(unemployment_rate_japan, Sex == 'All persons')\n\nData Manipulation - converting character columns to numeric, rounding off percetnage to 2 digits, and renaming columns appropriately\n\nunemployment_time_value = select(unemployment_all_persons, Year, Value)\nunemployment_time_value = unemployment_time_value %&gt;% \n  rename(Unemployment_Rate = 'Value')\n\nDoing an inner join on the GDP data frame and Unemployment Years data frame with the common column ‘Year’\n\ngdp_unemployment = merge(x = gdp_annual, y = unemployment_time_value, by = 'Year')\ngdp_unemployment\n\n   Year GDP_Annual_Growth Unemployment_Rate\n1  1968             12.88              1.88\n2  1969             12.48              1.83\n3  1970              2.45              1.98\n4  1971              4.70              2.13\n5  1972              8.41              2.39\n6  1973              8.03              2.34\n7  1974             -1.23              2.47\n8  1975              3.09              3.05\n9  1976              3.97              3.13\n10 1977              4.39              3.54\n11 1978              5.27              3.76\n12 1979              5.48              3.39\n13 1980              2.82              3.58\n14 1981              4.26              4.01\n15 1982              3.28              3.92\n16 1983              3.63              4.53\n17 1984              4.41              4.90\n18 1985              5.16              4.77\n19 1986              3.29              5.17\n20 1987              4.65              5.24\n21 1988              6.66              4.85\n22 1989              4.93              4.46\n23 1990              4.84              4.32\n24 1991              3.52              4.46\n25 1992              0.90              4.36\n26 1993             -0.46              5.11\n27 1994              1.08              5.45\n28 1995              2.63              6.09\n29 1996              3.13              6.73\n30 1997              0.98              6.64\n31 1998             -1.27              7.72\n32 1999             -0.33              9.28\n33 2000              2.76              9.20\n34 2001              0.39              9.71\n35 2002              0.04             10.04\n36 2003              1.54             10.16\n37 2004              2.19              9.47\n38 2005              1.80              8.65\n39 2006              1.37              8.00\n40 2007              1.48              7.70\n41 2008             -1.22              7.24\n42 2009             -5.69              9.08\n43 2010              4.10              9.22\n44 2011              0.02              8.02\n45 2012              1.37              7.95\n46 2013              2.01              6.88\n47 2014              0.30              6.29\n48 2015              1.56              5.52\n49 2016              0.75              5.12\n50 2017              1.68              4.60\n51 2018              0.64              3.76\n52 2019             -0.40              3.66\n53 2020             -4.15              4.58\n54 2021              2.56              4.62\n55 2022              0.95              4.20\n\n\nCreating an interactive line chart to depict the relationship between GDP Growth Rate and Unemployment Rate\n\nline_gdp_unemp = plot_ly(gdp_unemployment, x = ~Year) %&gt;% \n    add_trace(y = ~GDP_Annual_Growth, name = 'GDP Annual Growth (in Percentage)', type = 'scatter', mode = 'lines') %&gt;% \n    add_trace(y = ~Unemployment_Rate, name = 'Unemployment Rate (in Percentage)', type = 'scatter', mode = 'lines') %&gt;%\n    layout(xaxis = list(title = \"Years\", tickmode='linear', tickangle = -90),\n           yaxis = list(title = \"Percentage\"),\n           title = 'GDP Growth Rate vs Unemployment Rate \\n Japan (1968-2022)')\nline_gdp_unemp\n\n\n\n\n\nCreating a dataset with unemployment rate of all countries in the year 2022\n\ncountries_info = subset(lfs_sexage_raw, Age == \"15 to 24\" & Series == \"Unemployment rate\" & Time == \"2022\" & Sex == \"All persons\")\n\ncountries_info &lt;- countries_info[order(countries_info$Value), ]\n\nrow.names(countries_info) = NULL\n\nPlotting an interactive map with unemployment rate of all countries in the year 2022\n\nsuppressWarnings({\n  color_scale &lt;- colorRamp(c(\"red\", \"orange\", \"yellow\"))\n  \n  min_value &lt;- ifelse(length(countries_info$Value) &gt; 0, min(countries_info$Value, na.rm = TRUE), NA)\n  max_value &lt;- ifelse(length(countries_info$Value) &gt; 0, max(countries_info$Value, na.rm = TRUE), NA)\n\n  rounded_ticks &lt;- round(seq(min_value, max_value, length.out = 5), 2)\n  \n  fig &lt;- plot_ly(countries_info,\n                 type = \"scattergeo\",\n                 mode = \"markers\",\n                 locationmode = \"country names\",\n                 locations = ~Country,\n                 color = ~Value,\n                 text = ~paste(\"Country: \", Country, \"&lt;br&gt;UR: \", round(Value, 2)),\n                 colors = color_scale,\n                 marker = list(size = 10)) %&gt;%\n    layout(title = \"Youth Unemployment Rate in 2022\",\n           geo = list(\n             showframe = FALSE,\n             projection = list(type = 'mercator'),\n             bgcolor = \"lightblue\",\n             showcoastlines = TRUE,\n             showland = TRUE,\n             landcolor = \"lightgreen\",\n             showocean = TRUE,\n             oceancolor = \"lightblue\"\n           )) %&gt;%\n    colorbar(title = \"Youth Unemployment Rate(%)\",\n             tickvals = seq(min_value, max_value, length.out = 5),\n             ticktext = rounded_ticks)\n\n  fig\n})"
  },
  {
    "objectID": "Finalprocodes.html",
    "href": "Finalprocodes.html",
    "title": "FINAL PROJECT CODE",
    "section": "",
    "text": "packages &lt;- c( \"randomForest\",\"tree\",\"dplyr\", \"tidyverse\", \"plotly\", \"psych\", \"ISLR\", \"leaps\", \"reshape2\",\"readr\")\n\nfor (package in packages) {\n  if (!(package %in% installed.packages())) {\n    install.packages(package, dependencies = TRUE)\n  }\n}\n# Load libraries\nsuppressMessages({library(dplyr)\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(psych)\nlibrary(ISLR)\nlibrary(leaps)\nlibrary(reshape2)\nlibrary(readr)\nlibrary(tree)\nlibrary(randomForest)\nlibrary(caret)})\n\n\nurl &lt;- \"https://raw.githubusercontent.com/KyleWandel/STAT-515-Final-Project/main/breast-cancer-wisconsin.csv\"\ndf &lt;- read.table(url, header = TRUE, sep = \",\")\nstr(df)\n\n'data.frame':   699 obs. of  11 variables:\n $ id              : int  1000025 1002945 1015425 1016277 1017023 1017122 1018099 1018561 1033078 1033078 ...\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : chr  \"1\" \"10\" \"2\" \"4\" ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n\n\nTo make the dataset ready for analysis we removed the ID column, checked and removed all rows with missing data changed he response variable values to malignant (4) = 1 and benign (2) = 0.\nAfter cleaning the dataset, we looked at a summary statistics for each variable. For our sample there are 444 records that are identified as not being malignant (=0) and 239 records that are identified as being malignant (=1).\n\n# remove ID column \ndf &lt;- subset(df, select = -id) \n# Change column type\ndf$barenuclei &lt;- as.integer(df$barenuclei) \n\nWarning: NAs introduced by coercion\n\n# Look for missing values\ncolSums(is.na(df)) \n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n               0                0                0                0 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n               0               16                0                0 \n         mitoses         benormal \n               0                0 \n\n# omit missing values\ndf_clean &lt;- na.omit(df) \nstr(df_clean) \n\n'data.frame':   683 obs. of  10 variables:\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : int  1 10 2 4 1 10 10 1 1 1 ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...\n  ..- attr(*, \"names\")= chr [1:16] \"24\" \"41\" \"140\" \"146\" ...\n\n# Change response variable to 1 and 0\ndf_clean$benormal &lt;- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal)) \nsummary(df_clean) \n\n clumpthickness   uniformcellsize  uniformcellshape  margadhesion  \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.00  \n Median : 4.000   Median : 1.000   Median : 1.000   Median : 1.00  \n Mean   : 4.442   Mean   : 3.151   Mean   : 3.215   Mean   : 2.83  \n 3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n   epithelial       barenuclei     blandchromatin   normalnucleoli \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.00  \n Median : 2.000   Median : 1.000   Median : 3.000   Median : 1.00  \n Mean   : 3.234   Mean   : 3.545   Mean   : 3.445   Mean   : 2.87  \n 3rd Qu.: 4.000   3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n    mitoses          benormal     \n Min.   : 1.000   Min.   :0.0000  \n 1st Qu.: 1.000   1st Qu.:0.0000  \n Median : 1.000   Median :0.0000  \n Mean   : 1.603   Mean   :0.3499  \n 3rd Qu.: 1.000   3rd Qu.:1.0000  \n Max.   :10.000   Max.   :1.0000  \n\ntable(df_clean$benormal)\n\n\n  0   1 \n444 239 \n\n\nWe next wanted to identify if there were any patterns amongst the predictor variables in the dataset. First we looked at the correlations, histrograms and scatterplots of the variables using the pairs.panel() function.\n\npairs.panels(df_clean)\n\n\n\n\nFor the first model we used the cleaned dataset and all of the variables.\n\nmodel_1 &lt;- glm(benormal ~ ., data = df_clean, family = binomial) \nsummary(model_1) \n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_clean)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -10.10394    1.17488  -8.600  &lt; 2e-16 ***\nclumpthickness     0.53501    0.14202   3.767 0.000165 ***\nuniformcellsize   -0.00628    0.20908  -0.030 0.976039    \nuniformcellshape   0.32271    0.23060   1.399 0.161688    \nmargadhesion       0.33064    0.12345   2.678 0.007400 ** \nepithelial         0.09663    0.15659   0.617 0.537159    \nbarenuclei         0.38303    0.09384   4.082 4.47e-05 ***\nblandchromatin     0.44719    0.17138   2.609 0.009073 ** \nnormalnucleoli     0.21303    0.11287   1.887 0.059115 .  \nmitoses            0.53484    0.32877   1.627 0.103788    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 102.89  on 673  degrees of freedom\nAIC: 122.89\n\nNumber of Fisher Scoring iterations: 8\n\npar(mfrow = c(2, 2))\nplot(model_1)\n\n\n\n\nIn this model the variables clumpthickness, margadhesion, barenuclei, blandchromatin were considered the only variables had a significant impact on the response variables with p-values less than .05. The overall model had an AIC of 122.89.\nNext, we wanted to create a new model after logging our variables.\n\nvariables_to_log &lt;- c(\"mitoses\", \"normalnucleoli\", \"blandchromatin\", \"epithelial\", \"margadhesion\", \"uniformcellshape\", \"uniformcellsize\",\"clumpthickness\") \ndf_log &lt;- df_clean \ndf_log[variables_to_log] &lt;- lapply(df_log[variables_to_log], log) \nmodel_2 &lt;- glm(benormal ~ ., data = df_log, family = binomial) \nsummary(model_2) \n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_log)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -9.31304    1.25953  -7.394 1.42e-13 ***\nclumpthickness    1.80864    0.59805   3.024  0.00249 ** \nuniformcellsize   0.50056    0.66380   0.754  0.45080    \nuniformcellshape  1.26038    0.74379   1.695  0.09016 .  \nmargadhesion      0.71750    0.39504   1.816  0.06933 .  \nepithelial       -0.04541    0.63630  -0.071  0.94310    \nbarenuclei        0.36117    0.09149   3.948 7.89e-05 ***\nblandchromatin    1.49565    0.61321   2.439  0.01473 *  \nnormalnucleoli    0.48867    0.35560   1.374  0.16938    \nmitoses           1.34541    0.74040   1.817  0.06920 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 107.02  on 673  degrees of freedom\nAIC: 127.02\n\nNumber of Fisher Scoring iterations: 8\n\npar(mfrow = c(2, 2))\nplot(model_2)\n\n\n\n\nFor this model the variables clumpthickness and barenuclei were considered the only variables had a significant impact on the response variables with p-values less than .05. The overall model had an AIC of 127.02.\nBased on the AIC of these two models, the non-logged model performed better. Now lets try and simplify the model.\n\nmodel_3 &lt;- glm(benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin, data = df_clean, family = binomial) \nsummary(model_3) \n\n\nCall:\nglm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -10.11370    1.03264  -9.794  &lt; 2e-16 ***\nclumpthickness   0.81166    0.12585   6.450 1.12e-10 ***\nmargadhesion     0.43412    0.11403   3.807 0.000141 ***\nbarenuclei       0.48136    0.08816   5.460 4.76e-08 ***\nblandchromatin   0.70154    0.15196   4.616 3.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 125.77  on 678  degrees of freedom\nAIC: 135.77\n\nNumber of Fisher Scoring iterations: 8\n\nmodel_3 \n\n\nCall:  glm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n   (Intercept)  clumpthickness    margadhesion      barenuclei  blandchromatin  \n      -10.1137          0.8117          0.4341          0.4814          0.7015  \n\nDegrees of Freedom: 682 Total (i.e. Null);  678 Residual\nNull Deviance:      884.4 \nResidual Deviance: 125.8    AIC: 135.8\n\nanova(model_1, model_3, test = \"Chisq\") \n\nAnalysis of Deviance Table\n\nModel 1: benormal ~ clumpthickness + uniformcellsize + uniformcellshape + \n    margadhesion + epithelial + barenuclei + blandchromatin + \n    normalnucleoli + mitoses\nModel 2: benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       673     102.89                          \n2       678     125.78 -5  -22.886 0.0003549 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs should be expected, creating a model using only the significant variables was worse at explaining the dataset. Using the Chisq test, we can also conclude that the more complex model is significantly better than the simpler model.\nUsing model_1 as the final model, lets see how accurate it is for prediction.\n\nglm.probs=predict(model_1,type=\"response\")\nglm.probs[1:10]\n\n          1           2           3           4           5           6 \n0.016046581 0.908808622 0.008137623 0.760934919 0.018166848 0.999973622 \n          7           8           9          10 \n0.056844170 0.004503358 0.011249056 0.006032371 \n\nglm.pred=rep(0,nrow(df_clean))\nglm.pred[glm.probs&gt;.5]=1\n\nglm.pred=as.factor(glm.pred)\ndf_clean$benormal=as.factor(df_clean$benormal)\ncm = table(glm.pred,df_clean$benormal)\nprint(cm)\n\n        \nglm.pred   0   1\n       0 434  11\n       1  10 228\n\n\nLooking at the confusion matrix this is a very good model with high predictability for both false positives and negatives. The % chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%).\n\nDecision Tree and Random Forest Modeling\nAnother modeling type we used for trying to predict whether a cell was cancerous or not was a random forest model. One of the biggest advantages of random forests is its versatility. It can be used for both regression and classification tasks, and it’s also easy to view the relative importance it assigns to the input features. One of the biggest problems in machine learning is overfitting, but most of the time this won’t happen thanks to the random forest classifier. If there are enough trees in the forest, the classifier won’t overfit the model.\nFirst, we looked at a decision tree model to determine the best spilt for node splitting. We did this by splitting the data into two sets, training and testing to train the model and then test its accuracy.\n\ndf_clean$benormal=as.integer(df_clean$benormal)\nset.seed(2) \ntrain = sample(1:nrow(df_clean), nrow(df_clean)/2) \ntree.df_clean=tree(benormal~.,df_clean,subset=train) \ncv.df_clean=cv.tree(tree.df_clean) \nplot(cv.df_clean$size,cv.df_clean$dev,type='b')\n\n\n\n\nBased on these results, it is best to include 6 variables in each split. Knowing this, we created a random forest model at the desired variable split.\n\ndf_clean &lt;- na.omit(df) \ndf_clean$benormal &lt;- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal))\ncancer_rf=randomForest(benormal~.,data=df_clean,subset=train,mtry=6,importance=TRUE) \n\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\n\nyhat.rf = predict(cancer_rf,newdata=df_clean[-train,]) \ndf_clean.test=df_clean[-train,\"benormal\"] \nmean((yhat.rf-df_clean.test)^2) #test set MSE \n\n[1] 0.03088145\n\ncancer_rf \n\n\nCall:\n randomForest(formula = benormal ~ ., data = df_clean, mtry = 6,      importance = TRUE, subset = train) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 6\n\n          Mean of squared residuals: 0.0294727\n                    % Var explained: 86.76\n\nplot(cancer_rf) \n\n\n\nvarImpPlot(cancer_rf) \n\n\n\n\nThe variable that is most important to reduce the mean standard error (MSE) is barenuceli and the variables that were deemed the most important to include in the node splitting were uniformcellsize and uniformcellshape. Overall, the model is very good with 88.7% of the variables explained. Looking at the confusion matrix:\n\nglm.probs=predict(cancer_rf,df_clean,type=\"response\")\nglm.probs[1:10]\n\n            1             2             3             4             5 \n-6.311618e-16  7.780000e-01 -5.944134e-16  3.439000e-01  4.533333e-03 \n            6             7             8             9            10 \n 1.000000e+00  2.551000e-01 -6.267209e-16  2.292000e-01 -5.822010e-16 \n\nglm.pred=rep(0,nrow(df_clean))\nglm.pred[glm.probs&gt;.5]=1\n\nglm.pred=as.factor(glm.pred)\ndf_clean$benormal=as.factor(df_clean$benormal)\ncm1 = table(glm.pred,df_clean$benormal)\nprint(cm1)\n\n        \nglm.pred   0   1\n       0 438   9\n       1   6 230\n\n\nThe percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%).\n\n\nPrincipal Component Analysis\nWe mentioned earlier that some of our variables were correlated but none were significantly correlated to each other. Also, in some of our other models, some of the variables were not significantly correlated to predicting the response variable. To examine this further, we did a principal component analysis on the predictor variables too see if reducing the number of variables of a data set naturally comes at the expense of accuracy while not losing too much accuracy.\n\ndf_clean$benormal &lt;- as.integer(df_clean$benormal)\nstates=row.names(df_clean)\napply(df_clean, 2, mean)\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        4.442167         3.150805         3.215227         2.830161 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        3.234261         3.544656         3.445095         2.869693 \n         mitoses         benormal \n        1.603221         1.349927 \n\napply(df_clean, 2, var)\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n       7.9566944        9.3951130        8.9316153        8.2057165 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n       4.9421089       13.2776950        6.0010133        9.3187722 \n         mitoses         benormal \n       3.0021597        0.2278116 \n\n# There isn't much difference in the mean and variance, so we do not need to scale/standardize the variables.\n# Calculate the principal components\npr.out=prcomp(df_clean, scale=TRUE)\nnames(pr.out)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\npr.out$center\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        4.442167         3.150805         3.215227         2.830161 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        3.234261         3.544656         3.445095         2.869693 \n         mitoses         benormal \n        1.603221         1.349927 \n\nhead(pr.out$x,n = 10)\n\n         PC1         PC2         PC3         PC4         PC5         PC6\n1   1.632138 -0.10110899  0.53066017  0.04867467 -0.13967887  0.27266403\n2  -1.091952 -0.36764796 -0.37608283 -0.33727673  1.66159818 -0.49947533\n3   1.747215 -0.06835623 -0.05452903 -0.08442398 -0.05762203 -0.12479945\n4  -1.123580 -0.30561252  0.32020004  1.60389615 -0.54780477  0.16977170\n5   1.517047 -0.06200488 -0.04883144 -0.28957594 -0.09371811  0.57460157\n6  -5.173918 -1.36302344 -0.65367495  0.40382274  0.40838925  0.39318524\n7   1.250797 -0.53179083 -0.59909575 -1.16253763  0.26500705 -1.70934020\n8   1.817759  0.03688650 -0.35718994  0.11869407 -0.03111154 -0.03121061\n9   1.714243  2.28289475  0.16547803 -0.59033209 -0.12926420 -0.30699255\n10  1.749457  0.02462355  0.31567378  0.12332678  0.02349157  0.20775672\n           PC7         PC8         PC9        PC10\n1   0.32271338 -0.41613912  0.14987849 -0.01320316\n2  -0.76488363 -0.51190377  1.43717566 -0.18341430\n3   0.33212748 -0.22014329  0.14173141 -0.02990047\n4  -0.18141468  1.53841728  1.21084570 -0.32073360\n5   0.09877523 -0.42777805  0.09395639  0.02496084\n6   0.34574434  0.13590736  0.52396579 -0.01704468\n7   0.10416365  0.10310453  0.89835584 -0.27270693\n8   0.41671423  0.04563756  0.03920288  0.22753908\n9   0.16385020  0.27850361 -0.07680255 -0.01644927\n10  0.07179972 -0.02809058  0.05914645 -0.26772940\n\npr.out$rotation=-pr.out$rotation\npr.out$x=-pr.out$x\nbiplot(pr.out, scale=0)\n\n\n\n(pr.var=pr.out$sdev^2) #variance of each PC\n\n [1] 6.73117831 0.79315381 0.54596815 0.46529869 0.38038147 0.31254327\n [7] 0.29602826 0.26121943 0.12634121 0.08788742\n\npve=pr.var/sum(pr.var)\npve\n\n [1] 0.673117831 0.079315381 0.054596815 0.046529869 0.038038147 0.031254327\n [7] 0.029602826 0.026121943 0.012634121 0.008788742\n\n# Scree plot\npar(mfrow =c(1,2))\nplot(pve, xlab=\"Principal Component\", \n     ylab=\"Proportion of Variance Explained\", ylim=c(0,1),type='b')\n\nplot(cumsum(pve), xlab=\"Principal Component\",\n     ylab=\"Cumulative Proportion of Variance Explained\", \n     ylim=c(0,1),type='b')"
  },
  {
    "objectID": "Finalprocodes.html#iii.-limitations",
    "href": "Finalprocodes.html#iii.-limitations",
    "title": "FINAL PROJECT CODE",
    "section": "iii. Limitations",
    "text": "iii. Limitations\nThere were no major limitations for this analysis but there were a few of things that needed to be done to the dataset in order to clean and make the dataset usable for analysis. First, we had to identify and remove all missing rows from the dataset. Second, we had to transform the response variable to be \"0\" and \"1\". Finally, many of the variables seemed to show a left skew making us question if the variables should be transformed or not. \nThere were only 699 samples for the dataset and although a solid number of samples, more samples would lead to a more predictable conclusion."
  },
  {
    "objectID": "Finalprocodes.html#iv.-conclusion",
    "href": "Finalprocodes.html#iv.-conclusion",
    "title": "FINAL PROJECT CODE",
    "section": "iv. Conclusion",
    "text": "iv. Conclusion\nIt seems that a significantly accurate model to predict if a cancerous cell could be malignant using the measurements recorded in this dataset. To test this, we created multiple regression models, a random forest model, and a PCA analysis to understand the variables more thoroughly.\nIn the PCA test we determined that the dataset's variance could be explained by simplifying and using only 2 of 9 predictor variables. We then created multiple logistic regression models and compared them to each other to choose the best one. After variable transformation and selection, we determined the best model would be to use all the variables. The percent chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%). We then decided to try and create an optimal best random forest model, starting with a best fit decision tree model. The created model resulted in an overall accuracy rate of almost 98% with the percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%). Based on the two models we created, the best model to use would be the random forest model because of its high accuracy and predictability."
  },
  {
    "objectID": "Finalprocodes.html#references",
    "href": "Finalprocodes.html#references",
    "title": "FINAL PROJECT CODE",
    "section": "References",
    "text": "References\n[1] Wolberg,WIlliam. (1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://doi.org/10.24432/C5HP4Z."
  },
  {
    "objectID": "Final.html",
    "href": "Final.html",
    "title": "FINAL PROJECT",
    "section": "",
    "text": "Group Number: 2\nAnusha Dusakanti, Kyle Wandel, Sumrah Shakeel"
  },
  {
    "objectID": "Final_Report_Webpage.html",
    "href": "Final_Report_Webpage.html",
    "title": "FINAL PROJECT CODE",
    "section": "",
    "text": "For the final project for our STAT 515 class, we were asked to find a dataset and perform a robust advanced analysis on the data. For this project we chose to use breast cancer screening data from the University of Wisconsin [1].This study aims to identify patterns and indicators that could potentially predict the signs of malignant cancerous cells. Through meticulous analysis, the paper investigates various aspects, including a deep dive into the predictor variables and their relationship to each other and the response variable, the creation of various statistical models to predict cancerous cells and then finally a comparison of models to choose the best one. By scrutinizing these factors, this research hopes to make discovering breast cancer in patients easier and earlier."
  },
  {
    "objectID": "Final_Report_Webpage.html#abstract",
    "href": "Final_Report_Webpage.html#abstract",
    "title": "FINAL PROJECT CODE",
    "section": "",
    "text": "For the final project for our STAT 515 class, we were asked to find a dataset and perform a robust advanced analysis on the data. For this project we chose to use breast cancer screening data from the University of Wisconsin [1].This study aims to identify patterns and indicators that could potentially predict the signs of malignant cancerous cells. Through meticulous analysis, the paper investigates various aspects, including a deep dive into the predictor variables and their relationship to each other and the response variable, the creation of various statistical models to predict cancerous cells and then finally a comparison of models to choose the best one. By scrutinizing these factors, this research hopes to make discovering breast cancer in patients easier and earlier."
  },
  {
    "objectID": "Final_Report_Webpage.html#i.-introduction",
    "href": "Final_Report_Webpage.html#i.-introduction",
    "title": "FINAL PROJECT CODE",
    "section": "i. Introduction",
    "text": "i. Introduction\nBreast cancer is one of the most common cancers in the world. While the pharmaceutical industry has invested quite a bit in trying to find a definitive cure to this cancer, it still raises the need for more analysis to be done on breast cancer data so that a cancerous tumor can be caught in the early stages. We wanted to see if it was possible to identify the potential emergence of breast cancer in women based on different features of the tumor cells. This dataset seemed like a good fit since it has 9 predictor variables, and the outcome variable would indicate whether the tumor can be classified as malignant (cancerous) or benign (non-cancerous). \nThe dataset we choose to perform this research is from Dr. William Wolberg and his clinical studies from 1989 to 1991. This dataset is very well known and highly integrable due to the amount of research conducted using this data. Below is a list and description of the 9 predictor variables and the 1 response variable (benormal).  \n\nclumpthickness: (1-10). Benign cells tend to be grouped in monolayers, while cancerous cells are often grouped in multilayers.\nuniformcellsize (1-10). Cancer cells tend to vary in size and shape. \nuniformcellshape (1-10). Cancer cells tend to vary in shape and size. \nmargadhesion: (1-10). Normal cells tend to stick together, while cancer cells tend to lose this ability, so the loss of adhesion is a sign of malignancy. \nepithelial: (1-10). It is related to the uniformity mentioned above. Epithelial cells that are significantly enlarged may be malignant. \nbarenuclei: (1-10). This term is used for nuclei not surrounded by cytoplasm (the rest of the cell). Those are typically seen in benign tumors. \nblandchromatin: (1-10). Describes a uniform “texture” of the nucleus seen in benign cells. In cancer cells, the chromatin tends to be more coarse and to form clumps. \nnormalnucleoli: (1-10). Nucleoli are small structures seen in the nucleus. In normal cells, the nucleolus is usually very small, if visible. The nucleoli become more prominent in cancer cells, and sometimes there are multiple. \nmitoses: (1-10). Cancer is essentially a disease of uncontrolled mitosis. \nbenormal: (2 or 4). Benign (non-cancerous) or malignant (cancerous) lump in a breast. ii. Materials and Methods\n\nThe University of Wisconsin breast cancer data from William Wolberg has 699 observations and 10 variables, the first variable represents the ID of the sample and the last column “benornal” represents the classification/response variable (for benign, 4 for malignant).\n\n\n'data.frame':   699 obs. of  11 variables:\n $ id              : int  1000025 1002945 1015425 1016277 1017023 1017122 1018099 1018561 1033078 1033078 ...\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : chr  \"1\" \"10\" \"2\" \"4\" ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n\n\nUsing this dataset we wanted to try and answer the following research questions:\nQuestion 1: What are the variables displaying significant correlation?\nQuestion 2: How does Principal Component Analysis contribute to understanding the variance explained by principal components in our dataset?\nQuestion 3: Can a logistic regression model be created to accurately predict malignant breast cancer cells?\nQuestion 4: Can a random forest model be created to accurately predict the likelihood of a cell being malignant?\nTo make the dataset ready for analysis we removed the ID column, checked and removed all rows with missing data changed he response variable values to malignant (4) = 1 and benign (2) = 0.\n\n\nWarning: NAs introduced by coercion\n\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n               0                0                0                0 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n               0               16                0                0 \n         mitoses         benormal \n               0                0 \n\n\n'data.frame':   683 obs. of  10 variables:\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : int  1 10 2 4 1 10 10 1 1 1 ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...\n  ..- attr(*, \"names\")= chr [1:16] \"24\" \"41\" \"140\" \"146\" ...\n\n\n clumpthickness   uniformcellsize  uniformcellshape  margadhesion  \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.00  \n Median : 4.000   Median : 1.000   Median : 1.000   Median : 1.00  \n Mean   : 4.442   Mean   : 3.151   Mean   : 3.215   Mean   : 2.83  \n 3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n   epithelial       barenuclei     blandchromatin   normalnucleoli \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.00  \n Median : 2.000   Median : 1.000   Median : 3.000   Median : 1.00  \n Mean   : 3.234   Mean   : 3.545   Mean   : 3.445   Mean   : 2.87  \n 3rd Qu.: 4.000   3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n    mitoses          benormal     \n Min.   : 1.000   Min.   :0.0000  \n 1st Qu.: 1.000   1st Qu.:0.0000  \n Median : 1.000   Median :0.0000  \n Mean   : 1.603   Mean   :0.3499  \n 3rd Qu.: 1.000   3rd Qu.:1.0000  \n Max.   :10.000   Max.   :1.0000  \n\n\n\n  0   1 \n444 239 \n\n\nAfter cleaning the dataset, we looked at a summary of the statistics for each variable. For our sample there are 444 records that are identified as not being malignant (=0) and 239 records that are identified as being malignant (=1).\nWe next wanted to identify if there were any patterns amongst the predictor variables in the dataset. First we looked at the correlations, histrograms and scatterplots of the variables using the pairs.panel() function.\n\n\n\n\n\nSome of the variables showed correlations to each other, but none were deemed significant by the corr.test() function. But one thing we did notice was that many of the variables exhibited a right skew with their means larger than their medians. We could potentially log() the variables to make them more uniform."
  },
  {
    "objectID": "Final_Report_Webpage.html#ii.-materials-and-methods",
    "href": "Final_Report_Webpage.html#ii.-materials-and-methods",
    "title": "FINAL PROJECT CODE",
    "section": "ii. Materials and Methods",
    "text": "ii. Materials and Methods\n\nPrincipal Component Analysis\nWe mentioned earlier that some of our variables were correlated but none were significantly correlated to each other. Also, in some of our other models, some of the variables were not significantly correlated to predicting the response variable. To examine this further, we did a principal component analysis on the predictor variables too see if reducing the number of variables of a data set naturally comes at the expense of accuracy while not losing too much accuracy.\nWe first took a look a the mean and variances of the variables in the dataset to see if the variables should be scaled or not. Below are the means an variances of the variables:\n\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        4.442167         3.150805         3.215227         2.830161 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        3.234261         3.544656         3.445095         2.869693 \n         mitoses \n        1.603221 \n\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        7.956694         9.395113         8.931615         8.205717 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        4.942109        13.277695         6.001013         9.318772 \n         mitoses \n        3.002160 \n\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        2.820761         3.065145         2.988581         2.864562 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        2.223085         3.643857         2.449697         3.052666 \n         mitoses \n        1.732674 \n\n\nBased on these results the following variables exhibit some significant diversity across the dataset; clumpthickness, uniformcellsize, uniformcellshape, margadhesion, barenuclei and normalnucleoli. The following variables showed some moderate variability across the dataset; epithelial, blandchromatin, and mitoses. Because of these results it would be best to scale the variables for analysis.\nAfter running a PCA analysis found that most of the variables are grouped indicating that there are similar observations based on the variable values. There are not too many outliers to indicate any unusual observations.\n\n\n\n\n\nLooking at the bigplot mitoses has the largest contribution when looking at the variables to the corresponding principal component. All of the variables, except for mitoses are positively correlated. Most of the variables are closer to all the other variables except for mitoses, further indicating that they are strongly influenced by these corresponding variables. Looking at the axis’ of the graph PC1 explains the most variance in the data as it has the longer axis than PC2.\nThe following graph is the scree plot for the PCA which is used to provide a simple yet effective way to see balance and the trade-off between retaining information and reducing dimensionality in your data.\n\n\n[1] 5.89949935 0.77594689 0.53925224 0.45962745 0.38027583 0.30187645 0.29440271\n[8] 0.26073586 0.08838322\n\n\n[1] 0.655499928 0.086216321 0.059916916 0.051069717 0.042252870 0.033541828\n[7] 0.032711413 0.028970651 0.009820358\n\n\n\n\n\nLooking at this graph we can easily identify that there is a large drop off-point after the first PCA, indicating that adding an additional principal component does not significantly add value at explaining the variability in the data.\nThe following graph shows cumulative proportion of variance that each principal components adds.\n\n\n\n\n\nLooking at this graph it seems that 4 principal components would be needed to explain over 80% of the variance.\n\n\nLogistic Regression Model\nWe decided to develop a Logistic regression model to see if we could develop a model that could be used to predict if a cell was cancerous or not. Because our outcome can only be one of two things (cell is malignant or benign) we should be using a classification model and logistic regression is a simple model which is much easier to set up and train initially than other machine learning models.\nFor the first model we used the cleaned dataset and all of the variables.\n\n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_clean)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -10.10394    1.17488  -8.600  &lt; 2e-16 ***\nclumpthickness     0.53501    0.14202   3.767 0.000165 ***\nuniformcellsize   -0.00628    0.20908  -0.030 0.976039    \nuniformcellshape   0.32271    0.23060   1.399 0.161688    \nmargadhesion       0.33064    0.12345   2.678 0.007400 ** \nepithelial         0.09663    0.15659   0.617 0.537159    \nbarenuclei         0.38303    0.09384   4.082 4.47e-05 ***\nblandchromatin     0.44719    0.17138   2.609 0.009073 ** \nnormalnucleoli     0.21303    0.11287   1.887 0.059115 .  \nmitoses            0.53484    0.32877   1.627 0.103788    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 102.89  on 673  degrees of freedom\nAIC: 122.89\n\nNumber of Fisher Scoring iterations: 8\n\n\n\nCall:  glm(formula = benormal ~ ., family = binomial, data = df_clean)\n\nCoefficients:\n     (Intercept)    clumpthickness   uniformcellsize  uniformcellshape  \n       -10.10394           0.53501          -0.00628           0.32271  \n    margadhesion        epithelial        barenuclei    blandchromatin  \n         0.33064           0.09664           0.38302           0.44719  \n  normalnucleoli           mitoses  \n         0.21303           0.53484  \n\nDegrees of Freedom: 682 Total (i.e. Null);  673 Residual\nNull Deviance:      884.4 \nResidual Deviance: 102.9    AIC: 122.9\n\n\nIn this model the variables clumpthickness, margadhesion, barenuclei, blandchromatin were considered the only variables had a significant impact on the response variables with p-values less than .05. The overall model had an AIC of 122.89.\nNext, we wanted to create a new model after logging our variables.\n\n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_log)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -9.31304    1.25953  -7.394 1.42e-13 ***\nclumpthickness    1.80864    0.59805   3.024  0.00249 ** \nuniformcellsize   0.50056    0.66380   0.754  0.45080    \nuniformcellshape  1.26038    0.74379   1.695  0.09016 .  \nmargadhesion      0.71750    0.39504   1.816  0.06933 .  \nepithelial       -0.04541    0.63630  -0.071  0.94310    \nbarenuclei        0.36117    0.09149   3.948 7.89e-05 ***\nblandchromatin    1.49565    0.61321   2.439  0.01473 *  \nnormalnucleoli    0.48867    0.35560   1.374  0.16938    \nmitoses           1.34541    0.74040   1.817  0.06920 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 107.02  on 673  degrees of freedom\nAIC: 127.02\n\nNumber of Fisher Scoring iterations: 8\n\n\n\nCall:  glm(formula = benormal ~ ., family = binomial, data = df_log)\n\nCoefficients:\n     (Intercept)    clumpthickness   uniformcellsize  uniformcellshape  \n        -9.31304           1.80864           0.50056           1.26038  \n    margadhesion        epithelial        barenuclei    blandchromatin  \n         0.71750          -0.04541           0.36117           1.49565  \n  normalnucleoli           mitoses  \n         0.48867           1.34541  \n\nDegrees of Freedom: 682 Total (i.e. Null);  673 Residual\nNull Deviance:      884.4 \nResidual Deviance: 107  AIC: 127\n\n\nFor this model the variables clumpthickness and barenuclei were considered the only variables had a significant impact on the response variables with p-values less than .05. The overall model had an AIC of 127.02.\nBased on the AIC of these two models, the non-logged model performed better. Now lets try and simplify the model.\n\n\n\nCall:\nglm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -10.11370    1.03264  -9.794  &lt; 2e-16 ***\nclumpthickness   0.81166    0.12585   6.450 1.12e-10 ***\nmargadhesion     0.43412    0.11403   3.807 0.000141 ***\nbarenuclei       0.48136    0.08816   5.460 4.76e-08 ***\nblandchromatin   0.70154    0.15196   4.616 3.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 125.77  on 678  degrees of freedom\nAIC: 135.77\n\nNumber of Fisher Scoring iterations: 8\n\n\n\nCall:  glm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n   (Intercept)  clumpthickness    margadhesion      barenuclei  blandchromatin  \n      -10.1137          0.8117          0.4341          0.4814          0.7015  \n\nDegrees of Freedom: 682 Total (i.e. Null);  678 Residual\nNull Deviance:      884.4 \nResidual Deviance: 125.8    AIC: 135.8\n\n\nAnalysis of Deviance Table\n\nModel 1: benormal ~ clumpthickness + uniformcellsize + uniformcellshape + \n    margadhesion + epithelial + barenuclei + blandchromatin + \n    normalnucleoli + mitoses\nModel 2: benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       673     102.89                          \n2       678     125.78 -5  -22.886 0.0003549 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs should be expected, creating a model using only the significant variables was worse at explaining the dataset. Using the Chisq test, we can also conclude that the more complex model is significantly better than the simpler model.\nUsing model_1 as the final model, lets see how accurate it is for prediction.\n\n\n          1           2           3           4           5           6 \n0.016046581 0.908808622 0.008137623 0.760934919 0.018166848 0.999973622 \n          7           8           9          10 \n0.056844170 0.004503358 0.011249056 0.006032371 \n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 434  11\n         1  10 228\n                                          \n               Accuracy : 0.9693          \n                 95% CI : (0.9534, 0.9809)\n    No Information Rate : 0.6501          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.9324          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.9775          \n            Specificity : 0.9540          \n         Pos Pred Value : 0.9753          \n         Neg Pred Value : 0.9580          \n             Prevalence : 0.6501          \n         Detection Rate : 0.6354          \n   Detection Prevalence : 0.6515          \n      Balanced Accuracy : 0.9657          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nLooking at the confusion matrix this is a very good model with high predictability for both false positives and negatives. The % chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%).\n\n\nDecision Tree and Random Forest Modeling\nAnother modeling technique we used for predicting whether a cell was cancerous or not was a random forest model. One of the biggest advantages of random forests is its versatility. It can be used for both regression and classification tasks, and it’s also easy to view the relative importance it assigns to the input features. One of the biggest problems in machine learning is overfitting, but most of the time this won’t happen thanks to the random forest classifier. If there are enough trees in the forest, the classifier won’t overfit the model.\nFirst, we looked at a decision tree model to determine the best spilt for node splitting. We did this by splitting the data into two sets, training and testing to train the model and then test its accuracy.\nFor this first model we included all of the variables in the dataset.\n\n\n\n\n\n\nRegression tree:\ntree(formula = benormal ~ ., data = df_clean, subset = train)\nVariables actually used in tree construction:\n[1] \"uniformcellshape\" \"clumpthickness\"   \"barenuclei\"       \"epithelial\"      \nNumber of terminal nodes:  5 \nResidual mean deviance:  0.02505 = 8.416 / 336 \nDistribution of residuals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.95240 -0.00495 -0.00495  0.00000  0.04762  0.99500 \n\n\nBased on this model alone we have a very strong model with a mean squared error (MSE) of just .025.\nWe then wanted to see if we could make the model better by keeping the residual difference low by pruning the tree and finding the lowest number of nodes to create a split with. Looking at the cross-validated decision tree graph below it looks like splitting the tree using 3 nodes is best.\n\n\n\n\n\nAfter pruning the tree and using 3 nodes to spilt the data below is the resulting model.\n\n\n\nRegression tree:\nsnip.tree(tree = tree.df_clean, nodes = c(2L, 6L))\nVariables actually used in tree construction:\n[1] \"uniformcellshape\" \"barenuclei\"      \nNumber of terminal nodes:  3 \nResidual mean deviance:  0.04432 = 14.98 / 338 \nDistribution of residuals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.95240 -0.01914 -0.01914  0.00000  0.04762  0.98090 \n\n\n\n\n\nThis is another strong model with a MSE of just .039. When comparing these models, their resdidual variances are very similar, as such we would likely choose the more simple model.\nLets now use a random forest model to prevent any potential overfitting of our decision tree model.\n\n\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\n\n\n[1] 0.02856504\n\n\nBy creating a random forest model we were able to reduce the MSE from .039 to .026\n\n\n\n\n\nTaking a look a which variables were most important in the model.\n\n\n\n\n\n\n\n\nThe variable that is most important to reduce the mean standard error (MSE) is barenuceli and the variables that were deemed the most important to include in the node splitting were uniformcellsize and uniformcellshape. Overall, the model is very good with 88.7% of the variables explained. Looking at the confusion matrix:\n\n\n            1             2             3             4             5 \n-6.231682e-16  7.668333e-01 -6.217249e-16  3.937667e-01  1.412692e-02 \n            6             7             8             9            10 \n 9.996000e-01  2.192000e-01 -6.310508e-16  1.061333e-01  7.692308e-05 \n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 438  10\n         1   6 229\n                                          \n               Accuracy : 0.9766          \n                 95% CI : (0.9622, 0.9866)\n    No Information Rate : 0.6501          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.9483          \n                                          \n Mcnemar's Test P-Value : 0.4533          \n                                          \n            Sensitivity : 0.9865          \n            Specificity : 0.9582          \n         Pos Pred Value : 0.9777          \n         Neg Pred Value : 0.9745          \n             Prevalence : 0.6501          \n         Detection Rate : 0.6413          \n   Detection Prevalence : 0.6559          \n      Balanced Accuracy : 0.9723          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nThe percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%)."
  },
  {
    "objectID": "Final_Report_Webpage.html#iii.-limitations",
    "href": "Final_Report_Webpage.html#iii.-limitations",
    "title": "FINAL PROJECT CODE",
    "section": "iii. Limitations",
    "text": "iii. Limitations\nThere were no major limitations for this analysis but there were a few of things that needed to be done to the dataset in order to clean and make the dataset usable for analysis. First, we had to identify and remove all missing rows from the dataset. Second, we had to transform the response variable to be “0” and “1”. Finally, many of the variables seemed to show a left skew making us question if the variables should be transformed or not. \nThere were only 699 samples for the dataset and although a solid number of samples, more samples would lead to a more predictable conclusion."
  },
  {
    "objectID": "Final_Report_Webpage.html#iv.-conclusion",
    "href": "Final_Report_Webpage.html#iv.-conclusion",
    "title": "FINAL PROJECT CODE",
    "section": "iv. Conclusion",
    "text": "iv. Conclusion\nIt seems that a significantly accurate model can be created to predict if a cancerous cell could be malignant using the measurements recorded in this dataset. To test this, we created multiple regression models, a random forest model, and a PCA analysis to understand the variables more thoroughly.  \nIn the PCA test we determined that the dataset’s variance could be explained by simplifying and using only 2 of 9 predictor variables. We then created multiple logistic regression models and compared them to each other to choose the best one. After variable transformation and selection, we determined the best model would be to use all the variables. The percent chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%). We then decided to try and create an optimal best random forest model, starting with a best fit decision tree model. The created model resulted in an overall accuracy rate of almost 98% with the percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%). Based on the two models we created, the best model to use would be the random forest model because of its high accuracy and predictability."
  },
  {
    "objectID": "Final_Report_Webpage.html#references",
    "href": "Final_Report_Webpage.html#references",
    "title": "FINAL PROJECT CODE",
    "section": "References",
    "text": "References\n[1] Wolberg,WIlliam. (1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://doi.org/10.24432/C5HP4Z. \n\n\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - James G, Witten D, Hastie T, Tibshirani R (2021). _ISLR: Data for an Introduction to Statistical Learning with Applications in R_. R package version 1.4, &lt;https://CRAN.R-project.org/package=ISLR&gt;.\n  - Kuhn, Max (2008). \"Building Predictive Models in R Using the caret Package.\" _Journal of Statistical Software_, *28*(5), 1–26. doi:10.18637/jss.v028.i05 &lt;https://doi.org/10.18637/jss.v028.i05&gt;, &lt;https://www.jstatsoft.org/index.php/jss/article/view/v028i05&gt;.\n  - Liaw A, Wiener M (2002). \"Classification and Regression by randomForest.\" _R News_, *2*(3), 18-22. &lt;https://CRAN.R-project.org/doc/Rnews/&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. &lt;https://easystats.github.io/report/&gt;.\n  - Miller TLboFcbA (2020). _leaps: Regression Subset Selection_. R package version 3.1, &lt;https://CRAN.R-project.org/package=leaps&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2023). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Ripley B (2023). _tree: Classification and Regression Trees_. R package version 1.0-43, &lt;https://CRAN.R-project.org/package=tree&gt;.\n  - Sarkar D (2008). _Lattice: Multivariate Data Visualization with R_. Springer, New York. ISBN 978-0-387-75968-5, &lt;http://lmdvr.r-forge.r-project.org&gt;.\n  - Sievert C (2020). _Interactive Web-Based Data Visualization with R, plotly, and shiny_. Chapman and Hall/CRC. ISBN 9781138331457, &lt;https://plotly-r.com&gt;.\n  - Wickham H (2007). \"Reshaping Data with the reshape Package.\" _Journal of Statistical Software_, *21*(12), 1-20. &lt;http://www.jstatsoft.org/v21/i12/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2023). _purrr: Functional Programming Tools_. R package version 1.0.2, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - William Revelle (2024). _psych: Procedures for Psychological, Psychometric, and Personality Research_. Northwestern University, Evanston, Illinois. R package version 2.4.3, &lt;https://CRAN.R-project.org/package=psych&gt;."
  },
  {
    "objectID": "Final.html#iii.-limitations",
    "href": "Final.html#iii.-limitations",
    "title": "FINAL PROJECT",
    "section": "iii. Limitations",
    "text": "iii. Limitations\nThere were no major limitations for this analysis but there were a few of things that needed to be done to the dataset in order to clean and make the dataset usable for analysis. First, we had to identify and remove all missing rows from the dataset. Second, we had to transform the response variable to be “0” and “1”. Finally, many of the variables seemed to show a left skew making us question if the variables should be transformed or not. \nThere were only 699 samples for the dataset and although a solid number of samples, more samples would lead to a more predictable conclusion."
  },
  {
    "objectID": "Final.html#iv.-conclusion",
    "href": "Final.html#iv.-conclusion",
    "title": "FINAL PROJECT",
    "section": "iv. Conclusion",
    "text": "iv. Conclusion\nIt seems that a significantly accurate model to predict if a cancerous cell could be malignant using the measurements recorded in this dataset. To test this, we created multiple regression models, a random forest model, and a PCA analysis to understand the variables more thoroughly.  \nIn the PCA test we determined that the dataset’s variance could be explained by simplifying and using only 2 of the 9 predictor variables. We then created multiple logistic regression models and compared them to each other to choose the best one. After variable transformation and selection, we determined the best model would be to use all the variables. The percent chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%). We then decided to try and create an optimal best random forest model, starting with a best fit decision tree model. The created model resulted in an overall accuracy rate of almost 98% with the percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%). Based on the two models we created, the best model to use would be the random forest model because of its high accuracy and predictability."
  },
  {
    "objectID": "Final.html#references",
    "href": "Final.html#references",
    "title": "FINAL PROJECT",
    "section": "References",
    "text": "References\n\nWolberg,WIlliam. (1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://doi.org/10.24432/C5HP4Z. \nGrolemund, G., & Wickham, H. (2011). “Dates and Times Made Easy with lubridate.” Journal of Statistical Software, 40(3), 1-25. [Online]. Available: https://www.jstatsoft.org/v40/i03/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). ISLR: Data for an Introduction to Statistical Learning with Applications in R. R package version 1.4. [Online]. Available: https://CRAN.R-project.org/package=ISLR\nKuhn, M. (2008). “Building Predictive Models in R Using the caret Package.” Journal of Statistical Software, 28(5), 1–26. doi:10.18637/jss.v028.i05 [Online]. Available: https://doi.org/10.18637/jss.v028.i05\nLiaw, A., & Wiener, M. (2002). “Classification and Regression by randomForest.” R News, 2(3), 18-22. [Online]. Available: https://CRAN.R-project.org/doc/Rnews/\nMakowski, D., Lüdecke, D., Patil, I., Thériault, R., Ben-Shachar, M., & Wiernik, B. (2023). “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. [Online]. Available: https://easystats.github.io/report/\nMiller, T. (2020). leaps: Regression Subset Selection. R package version 3.1. [Online]. Available: https://CRAN.R-project.org/package=leaps\nMüller, K., & Wickham, H. (2023). tibble: Simple Data Frames. R package version 3.2.1. [Online]. Available: https://CRAN.R-project.org/package=tibble\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. [Online]. Available: https://www.R-project.org/\nRipley, B. (2023). tree: Classification and Regression Trees. R package version 1.0-43. [Online]. Available: https://CRAN.R-project.org/package=tree\nSarkar, D. (2008). Lattice: Multivariate Data Visualization with R. Springer, New York. ISBN 978-0-387-75968-5. [Online]. Available: http://lmdvr.r-forge.r-project.org\nSievert, C. (2020). Interactive Web-Based Data Visualization with R, plotly, and shiny. Chapman and Hall/CRC. ISBN 9781138331457. [Online]. Available: https://plotly-r.com\nWickham, H. (2007). “Reshaping Data with the reshape Package.” Journal of Statistical Software, 21(12), 1-20. [Online]. Available: http://www.jstatsoft.org/v21/i12/\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4. [Online]. Available: https://ggplot2.tidyverse.org\nWickham, H. (2022). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.5.0. [Online]. Available: https://CRAN.R-project.org/package=stringr\nWickham, H. (2023). forcats: Tools for Working with Categorical Variables (Factors). R package version 1.0.0. [Online]. Available: https://CRAN.R-project.org/package=forcats\nWickham, H., et al. (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 [Online]. Available: https://doi.org/10.21105/joss.01686\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.3. [Online]. Available: https://CRAN.R-project.org/package=dplyr\nWickham, H., & Henry, L. (2023). purrr: Functional Programming Tools. R package version 1.0.2. [Online]. Available: https://CRAN.R-project.org/package=purrr\nWickham, H., Hester, J., & Bryan, J. (2023). readr: Read Rectangular Text Data. R package version 2.1.4. [Online]. Available: https://CRAN.R-project.org/package=readr\nWickham, H., Vaughan, D., & Girlich, M. (2023). tidyr: Tidy Messy Data. R package version 1.3.0. [Online]. Available: https://CRAN.R-project.org/package=tidyr\nRevelle, W. (2024). psych: Procedures for Psychological, Psychometric, and Personality Research. Northwestern University, Evanston, Illinois. R package version 2.4.3. [Online]. Available: https://CRAN.R-project.org/package=psych"
  },
  {
    "objectID": "Final_KW.html",
    "href": "Final_KW.html",
    "title": "FINAL PROJECT",
    "section": "",
    "text": "Group Number: 2\nAnusha Dusakanti, Kyle Wandel, Sumrah Shakeel"
  },
  {
    "objectID": "Final_KW.html#iii.-limitations",
    "href": "Final_KW.html#iii.-limitations",
    "title": "FINAL PROJECT",
    "section": "iii. Limitations",
    "text": "iii. Limitations\nThere were no major limitations for this analysis but there were a few of things that needed to be done to the dataset in order to clean and make the dataset usable for analysis. First, we had to identify and remove all missing rows from the dataset. Second, we had to transform the response variable to be “0” and “1”. Finally, many of the variables seemed to show a left skew making us question if the variables should be transformed or not. \nThere were only 699 samples for the dataset and although a solid number of samples, more samples would lead to a more predictable conclusion."
  },
  {
    "objectID": "Final_KW.html#iv.-conclusion",
    "href": "Final_KW.html#iv.-conclusion",
    "title": "FINAL PROJECT",
    "section": "iv. Conclusion",
    "text": "iv. Conclusion\nIt seems that a significantly accurate model to predict if a cancerous cell could be malignant using the measurements recorded in this dataset. To test this, we created multiple regression models, a random forest model, and a PCA analysis to understand the variables more thoroughly.  \nIn the PCA test we determined that the dataset’s variance could be explained by simplifying and using only 2 of the 9 predictor variables. We then created multiple logistic regression models and compared them to each other to choose the best one. After variable transformation and selection, we determined the best model would be to use all the variables. The percent chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%). We then decided to try and create an optimal best random forest model, starting with a best fit decision tree model. The created model resulted in an overall accuracy rate of almost 98% with the percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%). Based on the two models we created, the best model to use would be the random forest model because of its high accuracy and predictability."
  },
  {
    "objectID": "Final_KW.html#references",
    "href": "Final_KW.html#references",
    "title": "FINAL PROJECT",
    "section": "References",
    "text": "References\n\nWolberg,WIlliam. (1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://doi.org/10.24432/C5HP4Z. \nGrolemund, G., & Wickham, H. (2011). “Dates and Times Made Easy with lubridate.” Journal of Statistical Software, 40(3), 1-25. [Online]. Available: https://www.jstatsoft.org/v40/i03/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). ISLR: Data for an Introduction to Statistical Learning with Applications in R. R package version 1.4. [Online]. Available: https://CRAN.R-project.org/package=ISLR\nKuhn, M. (2008). “Building Predictive Models in R Using the caret Package.” Journal of Statistical Software, 28(5), 1–26. doi:10.18637/jss.v028.i05 [Online]. Available: https://doi.org/10.18637/jss.v028.i05\nLiaw, A., & Wiener, M. (2002). “Classification and Regression by randomForest.” R News, 2(3), 18-22. [Online]. Available: https://CRAN.R-project.org/doc/Rnews/\nMakowski, D., Lüdecke, D., Patil, I., Thériault, R., Ben-Shachar, M., & Wiernik, B. (2023). “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. [Online]. Available: https://easystats.github.io/report/\nMiller, T. (2020). leaps: Regression Subset Selection. R package version 3.1. [Online]. Available: https://CRAN.R-project.org/package=leaps\nMüller, K., & Wickham, H. (2023). tibble: Simple Data Frames. R package version 3.2.1. [Online]. Available: https://CRAN.R-project.org/package=tibble\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. [Online]. Available: https://www.R-project.org/\nRipley, B. (2023). tree: Classification and Regression Trees. R package version 1.0-43. [Online]. Available: https://CRAN.R-project.org/package=tree\nSarkar, D. (2008). Lattice: Multivariate Data Visualization with R. Springer, New York. ISBN 978-0-387-75968-5. [Online]. Available: http://lmdvr.r-forge.r-project.org\nSievert, C. (2020). Interactive Web-Based Data Visualization with R, plotly, and shiny. Chapman and Hall/CRC. ISBN 9781138331457. [Online]. Available: https://plotly-r.com\nWickham, H. (2007). “Reshaping Data with the reshape Package.” Journal of Statistical Software, 21(12), 1-20. [Online]. Available: http://www.jstatsoft.org/v21/i12/\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4. [Online]. Available: https://ggplot2.tidyverse.org\nWickham, H. (2022). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.5.0. [Online]. Available: https://CRAN.R-project.org/package=stringr\nWickham, H. (2023). forcats: Tools for Working with Categorical Variables (Factors). R package version 1.0.0. [Online]. Available: https://CRAN.R-project.org/package=forcats\nWickham, H., et al. (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. doi:10.21105/joss.01686 [Online]. Available: https://doi.org/10.21105/joss.01686\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.3. [Online]. Available: https://CRAN.R-project.org/package=dplyr\nWickham, H., & Henry, L. (2023). purrr: Functional Programming Tools. R package version 1.0.2. [Online]. Available: https://CRAN.R-project.org/package=purrr\nWickham, H., Hester, J., & Bryan, J. (2023). readr: Read Rectangular Text Data. R package version 2.1.4. [Online]. Available: https://CRAN.R-project.org/package=readr\nWickham, H., Vaughan, D., & Girlich, M. (2023). tidyr: Tidy Messy Data. R package version 1.3.0. [Online]. Available: https://CRAN.R-project.org/package=tidyr\nRevelle, W. (2024). psych: Procedures for Psychological, Psychometric, and Personality Research. Northwestern University, Evanston, Illinois. R package version 2.4.3. [Online]. Available: https://CRAN.R-project.org/package=psych"
  },
  {
    "objectID": "FinalWebpage.html",
    "href": "FinalWebpage.html",
    "title": "FINAL PROJECT CODE",
    "section": "",
    "text": "packages &lt;- c( \"randomForest\",\"tree\",\"dplyr\", \"tidyverse\", \"plotly\", \"psych\", \"ISLR\", \"leaps\", \"reshape2\",\"readr\")\nfor (package in packages) {\n  if (!(package %in% installed.packages())) {\n    install.packages(package, dependencies = TRUE)\n  }\n}\n# Load libraries\nsuppressMessages({library(dplyr)\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(psych)\nlibrary(ISLR)\nlibrary(leaps)\nlibrary(reshape2)\nlibrary(readr)\nlibrary(tree)\nlibrary(randomForest)\nlibrary(caret)})\n\n\nurl &lt;- \"https://raw.githubusercontent.com/KyleWandel/STAT-515-Final-Project/main/breast-cancer-wisconsin.csv\"\ndf &lt;- read.table(url, header = TRUE, sep = \",\")\nstr(df)\n\n'data.frame':   699 obs. of  11 variables:\n $ id              : int  1000025 1002945 1015425 1016277 1017023 1017122 1018099 1018561 1033078 1033078 ...\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : chr  \"1\" \"10\" \"2\" \"4\" ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n\n\nTo make the dataset ready for analysis we removed the ID column, checked and removed all rows with missing data changed he response variable values to malignant (4) = 1 and benign (2) = 0.\nAfter cleaning the dataset, we looked at a summary statistics for each variable. For our sample there are 444 records that are identified as not being malignant (=0) and 239 records that are identified as being malignant (=1).\n\n# remove ID column \ndf &lt;- subset(df, select = -id) \n# Change column type\ndf$barenuclei &lt;- as.integer(df$barenuclei) \n\nWarning: NAs introduced by coercion\n\n# Look for missing values\ncolSums(is.na(df)) \n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n               0                0                0                0 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n               0               16                0                0 \n         mitoses         benormal \n               0                0 \n\n# omit missing values\ndf_clean &lt;- na.omit(df) \nstr(df_clean) \n\n'data.frame':   683 obs. of  10 variables:\n $ clumpthickness  : int  5 5 3 6 4 8 1 2 2 4 ...\n $ uniformcellsize : int  1 4 1 8 1 10 1 1 1 2 ...\n $ uniformcellshape: int  1 4 1 8 1 10 1 2 1 1 ...\n $ margadhesion    : int  1 5 1 1 3 8 1 1 1 1 ...\n $ epithelial      : int  2 7 2 3 2 7 2 2 2 2 ...\n $ barenuclei      : int  1 10 2 4 1 10 10 1 1 1 ...\n $ blandchromatin  : int  3 3 3 3 3 9 3 3 1 2 ...\n $ normalnucleoli  : int  1 2 1 7 1 7 1 1 1 1 ...\n $ mitoses         : int  1 1 1 1 1 1 1 1 5 1 ...\n $ benormal        : int  2 2 2 2 2 4 2 2 2 2 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...\n  ..- attr(*, \"names\")= chr [1:16] \"24\" \"41\" \"140\" \"146\" ...\n\n# Change response variable to 1 and 0\ndf_clean$benormal &lt;- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal)) \nsummary(df_clean) \n\n clumpthickness   uniformcellsize  uniformcellshape  margadhesion  \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.00  \n Median : 4.000   Median : 1.000   Median : 1.000   Median : 1.00  \n Mean   : 4.442   Mean   : 3.151   Mean   : 3.215   Mean   : 2.83  \n 3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n   epithelial       barenuclei     blandchromatin   normalnucleoli \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.: 2.000   1st Qu.: 1.000   1st Qu.: 2.000   1st Qu.: 1.00  \n Median : 2.000   Median : 1.000   Median : 3.000   Median : 1.00  \n Mean   : 3.234   Mean   : 3.545   Mean   : 3.445   Mean   : 2.87  \n 3rd Qu.: 4.000   3rd Qu.: 6.000   3rd Qu.: 5.000   3rd Qu.: 4.00  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.00  \n    mitoses          benormal     \n Min.   : 1.000   Min.   :0.0000  \n 1st Qu.: 1.000   1st Qu.:0.0000  \n Median : 1.000   Median :0.0000  \n Mean   : 1.603   Mean   :0.3499  \n 3rd Qu.: 1.000   3rd Qu.:1.0000  \n Max.   :10.000   Max.   :1.0000  \n\ntable(df_clean$benormal)\n\n\n  0   1 \n444 239 \n\n\nWe next wanted to identify if there were any patterns amongst the predictor variables in the dataset. First we looked at the correlations, histrograms and scatterplots of the variables using the pairs.panel() function.\n\nplot_title &lt;- \"Pairs Panel Plot for Breast Cancer Dataset\"\npairs.panels(df_clean,  main = plot_title)\n\n\n\n\nPrincipal Component Analysis\nWe first took a look at the mean and variances of the variables in the dataset to see if the variables should be scaled or not. Below are the means an variances of the variables:\n\nPCA_df &lt;- df_clean[, -ncol(df_clean)]\nstates=row.names(PCA_df)\napply(PCA_df, 2, mean)\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        4.442167         3.150805         3.215227         2.830161 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        3.234261         3.544656         3.445095         2.869693 \n         mitoses \n        1.603221 \n\napply(PCA_df, 2, var)\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        7.956694         9.395113         8.931615         8.205717 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        4.942109        13.277695         6.001013         9.318772 \n         mitoses \n        3.002160 \n\napply(PCA_df, 2, sd)\n\n  clumpthickness  uniformcellsize uniformcellshape     margadhesion \n        2.820761         3.065145         2.988581         2.864562 \n      epithelial       barenuclei   blandchromatin   normalnucleoli \n        2.223085         3.643857         2.449697         3.052666 \n         mitoses \n        1.732674 \n\n# There is difference in the mean and variance, so we do should scale/standardize the variables.\n\nAfter running a PCA analysis found that most of the variables are grouped indicating that there are similar observations based on the variable values. There are not too many outliers to indicate any unusual observations.\n\n# Calculate the principal components\npr.out=prcomp(PCA_df, scale=TRUE)\npr.out$rotation=-pr.out$rotation\npr.out$x=-pr.out$x\nbiplot(pr.out, \n       scale = 0, \n       main = \"Biplot of PCA Results\", cex = 0.7)\n\n\n\n\nThe following graph is the scree plot for the PCA which is used to provide a simple yet effective way to see balance and the trade-off between retaining information and reducing dimensionality in your data.\n\n# Scree plot\n(pr.var=pr.out$sdev^2) #variance of each PC\n\n[1] 5.89949935 0.77594689 0.53925224 0.45962745 0.38027583 0.30187645 0.29440271\n[8] 0.26073586 0.08838322\n\npve=pr.var/sum(pr.var)\npve\n\n[1] 0.655499928 0.086216321 0.059916916 0.051069717 0.042252870 0.033541828\n[7] 0.032711413 0.028970651 0.009820358\n\npar(mfrow =c(1,2))\nplot(pve, main = \"Scree Plot for Variance Explained\",\n     xlab=\"Principal Component\", \n     ylab=\"Proportion of Variance Explained\", ylim=c(0,1),type='b')\n\n\n\n\nThe following graph shows cumulative proportion of variance that each principal components adds.\n\nplot(cumsum(pve), main = \"Scree Plot for Cumulative Variance Explained\",\n     xlab=\"Principal Component\",\n     ylab=\"Cumulative Proportion of Variance Explained\", \n     ylim=c(0,1),type='b')\n\n\n\n\nLogistic Regression\nFor the first model we used the cleaned dataset and all of the variables.\n\nmodel_1 &lt;- glm(benormal ~ ., data = df_clean, family = binomial) \nsummary(model_1) \n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_clean)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -10.10394    1.17488  -8.600  &lt; 2e-16 ***\nclumpthickness     0.53501    0.14202   3.767 0.000165 ***\nuniformcellsize   -0.00628    0.20908  -0.030 0.976039    \nuniformcellshape   0.32271    0.23060   1.399 0.161688    \nmargadhesion       0.33064    0.12345   2.678 0.007400 ** \nepithelial         0.09663    0.15659   0.617 0.537159    \nbarenuclei         0.38303    0.09384   4.082 4.47e-05 ***\nblandchromatin     0.44719    0.17138   2.609 0.009073 ** \nnormalnucleoli     0.21303    0.11287   1.887 0.059115 .  \nmitoses            0.53484    0.32877   1.627 0.103788    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 102.89  on 673  degrees of freedom\nAIC: 122.89\n\nNumber of Fisher Scoring iterations: 8\n\npar(mfrow = c(2, 2))\nplot(model_1)\n\n\n\n\nNext, we wanted to create a new model after logging our variables.\n\nvariables_to_log &lt;- c(\"mitoses\", \"normalnucleoli\", \"blandchromatin\", \"epithelial\", \"margadhesion\", \"uniformcellshape\", \"uniformcellsize\",\"clumpthickness\") \ndf_log &lt;- df_clean \ndf_log[variables_to_log] &lt;- lapply(df_log[variables_to_log], log) \nmodel_2 &lt;- glm(benormal ~ ., data = df_log, family = binomial) \nsummary(model_2) \n\n\nCall:\nglm(formula = benormal ~ ., family = binomial, data = df_log)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -9.31304    1.25953  -7.394 1.42e-13 ***\nclumpthickness    1.80864    0.59805   3.024  0.00249 ** \nuniformcellsize   0.50056    0.66380   0.754  0.45080    \nuniformcellshape  1.26038    0.74379   1.695  0.09016 .  \nmargadhesion      0.71750    0.39504   1.816  0.06933 .  \nepithelial       -0.04541    0.63630  -0.071  0.94310    \nbarenuclei        0.36117    0.09149   3.948 7.89e-05 ***\nblandchromatin    1.49565    0.61321   2.439  0.01473 *  \nnormalnucleoli    0.48867    0.35560   1.374  0.16938    \nmitoses           1.34541    0.74040   1.817  0.06920 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 107.02  on 673  degrees of freedom\nAIC: 127.02\n\nNumber of Fisher Scoring iterations: 8\n\npar(mfrow = c(2, 2))\nplot(model_2)\n\n\n\n\nBased on the AIC of these two models, the non-logged model performed better. Now lets try and simplify the model.\n\nmodel_3 &lt;- glm(benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin, data = df_clean, family = binomial) \nsummary(model_3) \n\n\nCall:\nglm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -10.11370    1.03264  -9.794  &lt; 2e-16 ***\nclumpthickness   0.81166    0.12585   6.450 1.12e-10 ***\nmargadhesion     0.43412    0.11403   3.807 0.000141 ***\nbarenuclei       0.48136    0.08816   5.460 4.76e-08 ***\nblandchromatin   0.70154    0.15196   4.616 3.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 884.35  on 682  degrees of freedom\nResidual deviance: 125.77  on 678  degrees of freedom\nAIC: 135.77\n\nNumber of Fisher Scoring iterations: 8\n\nmodel_3 \n\n\nCall:  glm(formula = benormal ~ clumpthickness + margadhesion + barenuclei + \n    blandchromatin, family = binomial, data = df_clean)\n\nCoefficients:\n   (Intercept)  clumpthickness    margadhesion      barenuclei  blandchromatin  \n      -10.1137          0.8117          0.4341          0.4814          0.7015  \n\nDegrees of Freedom: 682 Total (i.e. Null);  678 Residual\nNull Deviance:      884.4 \nResidual Deviance: 125.8    AIC: 135.8\n\nanova(model_1, model_3, test = \"Chisq\") \n\nAnalysis of Deviance Table\n\nModel 1: benormal ~ clumpthickness + uniformcellsize + uniformcellshape + \n    margadhesion + epithelial + barenuclei + blandchromatin + \n    normalnucleoli + mitoses\nModel 2: benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       673     102.89                          \n2       678     125.78 -5  -22.886 0.0003549 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nUsing model_1 as the final model, lets see how accurate it is for prediction.\n\nglm.probs=predict(model_1,type=\"response\")\nglm.probs[1:10]\n\n          1           2           3           4           5           6 \n0.016046581 0.908808622 0.008137623 0.760934919 0.018166848 0.999973622 \n          7           8           9          10 \n0.056844170 0.004503358 0.011249056 0.006032371 \n\nglm.pred=rep(0,nrow(df_clean))\nglm.pred[glm.probs&gt;.5]=1\nglm.pred=as.factor(glm.pred)\ndf_clean$benormal=as.factor(df_clean$benormal)\ncm = table(glm.pred,df_clean$benormal)\nprint(cm)\n\n        \nglm.pred   0   1\n       0 434  11\n       1  10 228\n\n\nDecision Tree and Random Forest Modeling\nFirst, we looked at a decision tree model to determine the best spilt for node splitting. We did this by splitting the data into two sets, training and testing to train the model and then test its accuracy.\n\ndf_clean$benormal=as.integer(df_clean$benormal)\nset.seed(2) \ntrain = sample(1:nrow(df_clean), nrow(df_clean)/2) \ntree.df_clean=tree(benormal~.,df_clean,subset=train) \nplot(tree.df_clean, )\ntitle(\"Breast Cancer Decision Tree\")\ntext(tree.df_clean,pretty=0)\n\n\n\nsummary(tree.df_clean)\n\n\nRegression tree:\ntree(formula = benormal ~ ., data = df_clean, subset = train)\nVariables actually used in tree construction:\n[1] \"uniformcellshape\" \"clumpthickness\"   \"barenuclei\"       \"epithelial\"      \nNumber of terminal nodes:  5 \nResidual mean deviance:  0.02505 = 8.416 / 336 \nDistribution of residuals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.95240 -0.00495 -0.00495  0.00000  0.04762  0.99500 \n\n\n\nplot(tree.df_clean)\ntitle(\"Breast Cancer Decision Tree\")\ntext(tree.df_clean, pretty = 0)\n\n\n\n\nChecking if pruning will improve them model.\n\ncv.df_clean=cv.tree(tree.df_clean)\nplot(cv.df_clean$size,cv.df_clean$dev,type='b',\n     main = \"Cross-Validated Tree Performance\",\n     xlab = \"Uniform Cell Size\", \n     ylab = \"Deviance\")\n\n\n\n\nAfter pruning the tree and using 3 nodes to spilt the data below is the resulting model.\n\nprune.df_clean=prune.tree(tree.df_clean,best=3)\nsummary(prune.df_clean)\n\n\nRegression tree:\nsnip.tree(tree = tree.df_clean, nodes = c(2L, 6L))\nVariables actually used in tree construction:\n[1] \"uniformcellshape\" \"barenuclei\"      \nNumber of terminal nodes:  3 \nResidual mean deviance:  0.04432 = 14.98 / 338 \nDistribution of residuals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.95240 -0.01914 -0.01914  0.00000  0.04762  0.98090 \n\nplot(prune.df_clean)\ntitle(\"Pruned Decision Tree\")\ntext(prune.df_clean,pretty=0)\n\n\n\n\nThis is another strong model with a MSE of just .039. When comparing these models, their resdidual variances are very similar, as such we would likely choose the more simple model.\nLets now use a random forest model to prevent any potential overfitting of our decision tree model.\n\ndf_clean &lt;- na.omit(df) \ndf_clean$benormal &lt;- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal))\n\nCreating a random forest model\n\ncancer_rf=randomForest(benormal~.,data=df_clean,subset=train,mtry=3,importance=TRUE)\n\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\n\nyhat.rf = predict(cancer_rf,newdata=df_clean[-train,])\ndf_clean.test=df_clean[-train,\"benormal\"]#testing y values\nmean((yhat.rf-df_clean.test)^2) #test set MSE\n\n[1] 0.02856504\n\n\nBy creating a random forest model we were able to reduce the MSE from .039 to .026\n\n# Plotting the forest\nplot(cancer_rf, \n     main = \"Random Forest Plot for Error Rate vs Trees\")\ngrid()\n\n\n\n\nTaking a look a which variables were most important in the model.\n\nplot(cancer_rf)\n\n\n\nvarImpPlot(cancer_rf, main = \"Variable Importance Plot\")\n\n\n\n\nLooking at the confusion matrix:\n\nglm.probs=predict(cancer_rf,df_clean,type=\"response\")\nglm.probs[1:10]\n\n            1             2             3             4             5 \n-6.231682e-16  7.668333e-01 -6.217249e-16  3.937667e-01  1.412692e-02 \n            6             7             8             9            10 \n 9.996000e-01  2.192000e-01 -6.310508e-16  1.061333e-01  7.692308e-05 \n\nglm.pred=rep(0,nrow(df_clean))\nglm.pred[glm.probs&gt;.5]=1\nglm.pred=as.factor(glm.pred)\ndf_clean$benormal=as.factor(df_clean$benormal)\nconfusionMatrix(glm.pred,df_clean$benormal)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 438  10\n         1   6 229\n                                          \n               Accuracy : 0.9766          \n                 95% CI : (0.9622, 0.9866)\n    No Information Rate : 0.6501          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.9483          \n                                          \n Mcnemar's Test P-Value : 0.4533          \n                                          \n            Sensitivity : 0.9865          \n            Specificity : 0.9582          \n         Pos Pred Value : 0.9777          \n         Neg Pred Value : 0.9745          \n             Prevalence : 0.6501          \n         Detection Rate : 0.6413          \n   Detection Prevalence : 0.6559          \n      Balanced Accuracy : 0.9723          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nThe percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%)."
  },
  {
    "objectID": "FinalReport.html",
    "href": "FinalReport.html",
    "title": "STAT515 FINAL PROJECT",
    "section": "",
    "text": "Group Number: 2\nAnusha Dusakanti, Kyle Wandel, Sumrah Shakeel"
  },
  {
    "objectID": "FinalReport.html#iii.-limitations",
    "href": "FinalReport.html#iii.-limitations",
    "title": "STAT515 FINAL PROJECT",
    "section": "iii. Limitations",
    "text": "iii. Limitations\nThere were no major limitations for this analysis but there were a few of things that needed to be done to the dataset in order to clean and make the dataset usable for analysis. First, we had to identify and remove all missing rows from the dataset. Second, we had to transform the response variable to be “0” and “1”. Finally, many of the variables seemed to show a left skew making us question if the variables should be transformed or not. \nThere were only 699 samples for the dataset and although a solid number of samples, more samples would lead to a more predictable conclusion."
  },
  {
    "objectID": "FinalReport.html#iv.-conclusion",
    "href": "FinalReport.html#iv.-conclusion",
    "title": "STAT515 FINAL PROJECT",
    "section": "iv. Conclusion",
    "text": "iv. Conclusion\nIt seems that a significantly accurate model to predict if a cancerous cell could be malignant using the measurements recorded in this dataset. To test this, we created multiple regression models, a random forest model, and a PCA analysis to understand the variables more thoroughly.  \nIn the PCA test we determined that the dataset’s variance could be explained by simplifying and using only 2 of the 9 predictor variables. We then created multiple logistic regression models and compared them to each other to choose the best one. After variable transformation and selection, we determined the best model would be to use all the variables. The percent chance the model falsely predicted cancer when not was 10/444 (2.2%) and the chance the model falsely predicted not having cancer when there was 11/239 (4.6%). We then decided to try and create an optimal best random forest model, starting with a best fit decision tree model. The created model resulted in an overall accuracy rate of almost 98% with the percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%). Based on the two models we created, the best model to use would be the random forest model because of its high accuracy and predictability."
  },
  {
    "objectID": "FinalReport.html#references",
    "href": "FinalReport.html#references",
    "title": "STAT515 FINAL PROJECT",
    "section": "References",
    "text": "References\n\nGrolemund, G., & Wickham, H. (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25. https://www.jstatsoft.org/v40/i03/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). ISLR: Data for an Introduction to Statistical Learning with Applications in R. R package version 1.4. https://CRAN.R-project.org/package=ISLR\nKuhn, M. (2008). Building Predictive Models in R Using the caret Package. Journal of Statistical Software, 28(5), 1–26. https://doi.org/10.18637/jss.v028.i05\nLiaw, A., & Wiener, M. (2002). Classification and Regression by randomForest. R News, 2(3), 18-22. https://CRAN.R-project.org/doc/Rnews/\nMakowski, D., Lüdecke, D., Patil, I., Thériault, R., Ben-Shachar, M., & Wiernik, B. (2023). Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption. CRAN. https://easystats.github.io/report/\nMiller, T. (2020). leaps: Regression Subset Selection. R package version 3.1. https://CRAN.R-project.org/package=leaps\nMüller, K., & Wickham, H. (2023). tibble: Simple Data Frames. R package version 3.2.1. https://CRAN.R-project.org/package=tibble\nRevelle, W. (2024). psych: Procedures for Psychological, Psychometric, and Personality Research. Northwestern University, Evanston, Illinois. R package version 2.4.3. https://CRAN.R-project.org/package=psych\nR Core Team. (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/Ripley, B. (2023). tree: Classification and Regression Trees. R package version 1.0-43. https://CRAN.R-project.org/package=tree\nSarkar, D. (2008). Lattice: Multivariate Data Visualization with R. Springer. http://lmdvr.r-forge.r-project.org\nSievert, C. (2020). Interactive Web-Based Data Visualization with R, plotly, and shiny. Chapman and Hall/CRC.\nWickham, H. (2007). Reshaping Data with the reshape Package. Journal of Statistical Software, 21(12), 1-20. http://www.jstatsoft.org/v21/i12/\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York.\nWickham, H. (2022). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.5.0. https://CRAN.R-project.org/package=stringr\nWickham, H. (2023). forcats: Tools for Working with Categorical Variables (Factors). R package version 1.0.0. https://CRAN.R-project.org/package=forcats\nWickham, H., et al. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.3. https://CRAN.R-project.org/package=dplyr\nWickham, H., & Henry, L. (2023). purrr: Functional Programming Tools. R package version 1.0.2. https://CRAN.R-project.org/package=purrr\nWickham, H., Hester, J., & Bryan, J. (2023). readr: Read Rectangular Text Data. R package version 2.1.4. https://CRAN.R-project.org/package=readr\nWickham, H., Vaughan, D., & Girlich, M. (2023). tidyr: Tidy Messy Data. R package version 1.3.0. https://CRAN.R-project.org/package=tidyrWolberg, W. (1992). Breast Cancer Wisconsin (Original). UCI Machine Learning Repository. https://doi.org/10.24432/C5HP4Z"
  },
  {
    "objectID": "aitpro.html",
    "href": "aitpro.html",
    "title": "AIT580 FINAL PROJECT",
    "section": "",
    "text": "Early Model-based Provisional Estimates of Drug Overdose, Suicide, and Transportation-related Deaths\nAIT-580-009\nProfessor Dr.Harry Foxwell | George Mason University\nAnusha Dusakanti\nGeorge Mason University\nFairfax, Virgina\nadusakan@gmu.edu\nAbstract\nThis project aims to understand the trends in drug overdose, suicide, and transportation-related deaths in the United States. The dataset, derived from death certificate data processed by the National Center for Health Statistics (NCHS), provides insights into mortality patterns for these causes of death. It is updated weekly as new data becomes available. These estimates, which are available by week and primary causes of death, give an early indicator of mortality trends and help in the identification of at-risk individuals and geographical locations. The dataset enables the analysis of intervention effectiveness and the identification of variables associated with effective policies for preventing these deaths. Using R, Python, and SQL for data transformations and visualizations, the research analyzes trends over time, examines the interaction of individual and environmental risk factors, and evaluates the impact of specific interventions on death rates.\nIntroduction\nUnintentional drug overdoses, suicides, and transportation-related accidents are major public health concerns in the United States, contributing significantly to preventable mortality. Understanding the trends, risk factors, and potential impact of interventions for these causes of death is crucial for developing effective prevention strategies and saving lives.\nThis study utilized the CDC’s dataset of model-based provisional estimates of weekly drug overdose, suicide, and transportation-related deaths to explore several key research questions:\n1.How have trends in these causes of death changed over time, and are there any seasonal patterns or long-term trends that can be identified?\n2. How do individual-level risk factors (e.g., mental health disorders, previous substance abuse, history of suicide attempts) combine with environmental factors (e.g., access to lethal means, social support networks) to affect the likelihood of dying from drug overdoses, suicides, and transportation-related accidents?\n3.Can the implementation of specific interventions or policies be associated with changes in mortality rates for these causes of death, and what characteristics of effective interventions can be identified from the data?\nBy addressing these questions, the study aims to provide insights that can inform the development and implementation of targeted, evidence-based strategies to reduce the burden of drug overdoses, suicides, and transportation-related deaths in the United States.\nLiterature Review\nMotor vehicle accidents, drug overdoses, and suicides are major public health concerns, accounting for a significant percentage of mortality rates, particularly among young people. Understanding the effectiveness of programs and policies designed to reduce these fatalities is critical for developing successful public health measures.\n\nKarpf and Williams [2] did a thorough examination of several legislative measures aimed at teen drivers and motor vehicle mortality. Their findings highlight the importance of initiatives such as raising the minimum licensing age, enforcing night curfews, and conditioning licenses on seat belt use in reducing fatalities among young drivers.\nThey suggest that postponing license for 16- and 17-year-olds, who have disproportionately high collision rates, could result in older and more experienced drivers replacing them, thus lowering overall motor vehicle fatalities. Furthermore, the implementation of night curfews is cited as an important approach for reducing fatalities involving young drivers.\nThe article ‘Trends in Drug Overdose Deaths Among US Adolescents’[3] indicates that beginning in 2020, teens suffered a significant spike in overdose mortality, particularly fentanyl-related deaths. This increase contrasts with declining drug usage rates among teens across the country, indicating a higher danger from illegal fentanyls, which are highly strong and sometimes added to counterfeit pills resembling prescription opioids or other substances. The highest overdose death rates were reported among American Indian and Alaska Native teenagers, indicating larger racial and ethnic disparities in overdose mortality. However, Latinx adolescents had very high rates compared to Latinx adults, indicating the need for additional research and intervention initiatives to address these disparities. Furthermore, the influence of specific COVID-19 pandemic elements, such as mental illness and disruptions in illicit drug markets, could not be adequately determined.\nThe article by Phillips and Luth[4] provides evidence supporting Tarde’s perspective, demonstrating how cultural norms and ideas of masculinity can influence suicide mortality rates. For example, the “gender paradox” in suicide - where women attempt suicide more often but men die by suicide at higher rates - suggests that cultural views play a key role. The authors note that suicide may be perceived as a solution to aging-related problems, particularly among older white men, reflecting the influence of cultural beliefs on suicidal actions.\nA recent report [5] by the National Center for Health Statistics examined early provisional estimates of drug overdose, suicide, and transportation-related deaths in the United States, utilizing nowcasting methods to account for reporting lags. \nThe analysis revealed several important trends:\nDrug Overdose: Since early 2019, there has been an increase in predicted counts; this acceleration became evident in February 2020. It’s possible that things have become worse lately.\nSuicide: There were strong seasonal trends, with mid-year numbers being higher and winter numbers being lower. Predicted counts in 2020 fell from March to June of that year, then slightly decreased from that point on, matching historical levels at first.\n\nDeaths related to transportation showed clear seasonal trends, peaking in the middle of the year and troughing in the winter, much like suicide rates. Forecast counts for 2020 first coincided with historical levels, then started to drop in March and April before rising in the following months.\n\nTrends unique to each jurisdiction were also looked at. All things considered, the research sheds light on the temporal trends of these mortality outcomes and points out possible variations in 2020 from prior years.\nMethodology\nTo address the research questions, a multi-pronged analytical approach was employed utilizing a combination of R, Python, and SQL.\nData Acquisition and Transformation\nThe primary dataset [1] used in this study was provided by the Centers for Disease Control and Prevention. This dataset was accessed and downloaded from the HealthData.gov portal.\nTo prepare the data for analysis, various data transformation and cleaning tasks were performed using R programming language. This included handling missing values, converting data types, and restructuring the data into a format suitable for further analysis.\nData Exploration and Visualization\nExploratory data analysis was conducted using a combination of R and Python. Visualizations such as line charts, bar plots, and heatmaps were created to identify trends, patterns, and relationships within the data. These visualizations were useful in addressing the first research question regarding changes in mortality rates over time and the identification of seasonal patterns or long-term trends.\nTargeted Analyses\nTo study the relationships between individual-level risk variables, environmental factors, and mortality rates, as well as the potential impact of initiatives and policies, SQL queries were used to extract relevant subsets of data. This included filtering the data based on geographic region, demographic factors, and time periods of interest.\n\nThe gathered data was then examined using R and Python, with statistical techniques and modeling approaches tailored to the research goals. This enabled a more in-depth investigation of the detailed interplay of individual, environmental, and policy-level factors and their impact on observed mortality trends.\nCloud-based Data Storage and Analytics\nTo facilitate efficient data storage, processing, and visualization, the dataset was uploaded to an Amazon S3 (Simple Storage Service) bucket. AWS Glue DataBrew was then employed to perform data cleaning, transformation, and exploratory analysis, generating interactive visualizations and insights to support the research objectives.\nThis combination of tools and techniques are leveraged to conduct a comprehensive analysis of the trends, risk factors, and potential impact of interventions related to drug overdose, suicide, and transportation-related deaths in the United States.\nResults\nThe data presented in Figure 1 shows the trends in drug overdose, suicide, and transportation-related deaths in the United States from 2016 to 2021. Several notable findings emerge from this data:\nDrug Overdose Deaths\nDrug overdose deaths were the highest among the three causes of death examined. The number of drug overdose deaths steadily increased over the time period, reaching a peak in 2020. This aligns with reports of a significant spike in overdose mortality, particularly involving fentanyl, during the COVID-19 pandemic period.\nSuicide Deaths\nSuicide deaths exhibited a different pattern, increasing from 2016 to 2018 before declining in the subsequent years. The data suggests that suicide mortality rates may have been impacted by the pandemic, with a drop observed in 2020.\nTransportation-Related Deaths\nDeaths related to transportation showed more variability over the 2016-2021 time frame. The data indicates that transportation-related fatalities were highest in 2020, potentially reflecting changes in travel patterns and behaviors during the pandemic, before declining again in 2021.\n\n\n\nFig 1\n\n\nThe line graphs in Figures 2 and 3 show the number of deaths due to different causes, over time in 2016 and 2021 respectively.\nIn both years, the data indicates that transportation-related deaths exhibited a clear seasonal pattern, with higher numbers observed during the August to November time period. The consistent seasonal pattern in transportation-related mortality across multiple years suggests that there are likely environmental, behavioral, or other factors that contribute to this cyclical trend. \n\n\n\nFig.2\n\n\n\n\n\nFig.3\n\n\nThe data presented in Figure 4 shows the number of suicide deaths across different states in the year 2020. The results indicate that two states with particularly high suicide rates were California and Florida.\nAccording to the information from the U.S. News & World Report article [6], these two states also had the largest homeless populations in the country in 2022. The article suggests that the high rates of homelessness in these states may be contributing to their elevated suicide mortality.\nIn contrast, the data shows that Colorado and Massachusetts had relatively lower suicide rates compared to other states. This aligns with the information from the CDC webpage, which indicates that these states have implemented various policies and interventions aimed at addressing suicide disparities and preventing suicide.\nThe findings highlight the complex interplay between individual, environmental, and policy-level factors that can influence suicide mortality. The high suicide rates observed in states with large homeless populations, such as California [7]and Florida, underscore the need to address social determinants of health and provide comprehensive support services for vulnerable populations.\nConversely, the lower suicide rates in states like Colorado and Massachusetts suggest that targeted policy interventions and suicide prevention programs can be effective in reducing suicide deaths. These results emphasize the importance of a multifaceted approach to suicide prevention that addresses both individual risk factors and the broader social and environmental contexts.\nThe search results indicate that Texas has a high Black population, with over 3.5 million Black residents, making it the state with the second largest Black population in the country. Additionally, the data shows that the suicide rate among Black individuals has seen a significant increase in recent years, with a 53.8% spike since 2019.\nThis suggests that the high suicide rate in Texas may be partially attributable to its large Black population, who face disproportionate challenges and discrimination that can contribute to mental health issues and suicidal behaviors.\nFurthermore, the search results indicate that states with larger Black populations, such as California, Florida, and Georgia, also tend to have higher overall suicide rates. This points to the role that systemic racism, social determinants of health, and lack of access to mental healthcare may play in driving disparities in suicide mortality.\n\n\n\nFig.4\n\n\nThe bar graph in Figure 5 shows the number of drug overdose-related deaths across different states in the United States. The data indicates that several states had particularly high rates of drug overdose mortality, including California, Florida, Ohio, Pennsylvania\nThese states with high drug overdose death rates align with the information from the U.S. News & World Report article, which identified California and Florida as having the largest homeless populations in the country[6]. The article suggests that the high rates of homelessness in these states may be contributing to elevated substance abuse and overdose mortality.\nAdditionally, the data on the Black population by state shows that Texas, California, Florida, and New York have some of the largest Black populations in the country[8]. Research has shown that the Black community has been disproportionately impacted by the opioid epidemic and rising overdose rates.\nIn contrast, the data indicates that states like Iowa, Rhode Island, and Colorado had relatively lower rates of drug overdose deaths. These states may have implemented more effective prevention and harm reduction strategies or have different demographic and socioeconomic profiles that confer lower overdose risk.\n\n\n\nFig.5\n\n\nThe bar graph in Figure 6 shows the number of transportation-related deaths in various states in the year 2020. The data indicates that some states had significantly lower rates of transportation-related fatalities compared to others.\nSpecifically, the states of Utah and Massachusetts had relatively lower numbers of transportation-related deaths.\nThe National Safety Council data[9] shows that in 2022, Massachusetts had the lowest motor vehicle fatality rate per 100 million miles traveled among all states. This suggests that Massachusetts has been effective in implementing policies and interventions to improve road safety and reduce transportation-related mortality.\nSimilarly, the Insurance Institute for Highway Safety (IIHS)[10] data indicates that Utah had one of the lower percentages of motor vehicle crash deaths occurring in single-vehicle crashes in 2021. Single-vehicle crashes are often associated with higher fatality rates, so Utah’s lower share of these types of crashes may contribute to its relatively lower transportation-related death toll.\nThese findings align with the data presented in Figure 6, which depicts Utah and Massachusetts as having fewer transportation-related deaths compared to other states. This highlights the importance of state-level policies, infrastructure, and safety programs in influencing transportation-related mortality outcomes across the country.\n\n\n\nFig.6\n\n\nLimitations\nDespite the useful insights gained from the analysis, certain limitations must be acknowledged when interpreting the results. Furthermore, excluding data from specific geographic areas may induce biases into the research, especially when comparing death rates across demographic categories. Without extensive data coverage, it is difficult to determine the entire amount of racial, ethnic, and socioeconomic gaps in mortality outcomes, limiting the depth of insights into underlying systemic inequities.\n\nFirstly, the dataset used in this study includes missing values for specific geographic regions, such as Alaska and Hawaii. The lack of data may result in partial representations of mortality patterns, thus skewing the overall study and limiting the accuracy of visualizations. As a result, the conclusions drawn from the research may not adequately account for the variation of mortality patterns across all locations of interest, limiting the findings’ generalizability.\nFuture Research\nExamining the Impact of Interventions and Policies: The dataset provides weekly estimates of mortality, which could be leveraged to assess the potential impact of specific interventions or policy changes implemented at the state or local level. Researchers could employ techniques like interrupted time series analysis to evaluate whether the introduction of new programs or policies was associated with changes in the observed mortality trends.\nInvestigating Racial and Ethnic Disparities: The search results indicate that certain racial and ethnic groups, such as American Indian/Alaska Native and Black populations, may be disproportionately affected by these causes of death. Further research could delve deeper into the underlying drivers of these disparities, exploring the role of social determinants of health, access to care, and systemic biases.\nAnalyzing Spatial and Temporal Patterns: The dataset provides information at the state level, which could be used to conduct spatial analyses to identify geographic hotspots or clusters of high mortality rates. Researchers could also investigate the seasonal patterns observed in the data, exploring potential environmental, behavioral, or other factors that may contribute to these cyclical trends.\nReferences\n[1] “Early Model-based Provisional Estimates of Drug Overdose, Suicide, and Transportation-related Deaths,” Data.gov, Mar. 30, 2022. https://catalog.data.gov/dataset/early-model-based-provisional-estimates-of-drug-overdose-suicide-and-transportation-relate-b35b2 (accessed Mar. 04, 2024).\n[2] R. S. Karpf and A. F. Williams, “Teenage drivers and motor vehicle deaths,” Accident Analysis & Prevention, vol. 15, no. 1. Elsevier BV, pp. 55–63, Feb. 1983. doi: 10.1016/0001-4575(83)90007-6.\n[3] J. Friedman, M. Godvin, C. L. Shover, J. P. Gone, H. Hansen, and D. L. Schriger, “Trends in Drug Overdose Deaths Among US Adolescents, January 2010 to June 2021,” JAMA, vol. 327, no. 14. American Medical Association (AMA), p. 1398, Apr. 12, 2022. doi: 10.1001/jama.2022.2847.\n[4] J. A. Phillips and E. A. Luth, “Beliefs About Suicide Acceptability in the United States: How Do They Affect Suicide Mortality?,” The Journals of Gerontology: Series B. Oxford University Press (OUP), Jan. 25, 2018. doi: 10.1093/geronb/gbx153.\n[5] L. Rossen, “VSRR-11: Early Provisional Estimates of Drug Overdose, Suicide, and Transportation-related Deaths: Nowcasting Methods to Account for Reporting Lags,” National Center for Health Statistics, Feb. 2021. doi: 10.15620/cdc:101132.\n[6] J. Haines, “States With the Largest Homeless Populations,” USNews, Apr. 06, 2023. https://www.usnews.com/news/best-states/articles/states-with-the-most-homeless-people\n[7] M. Kendall, “It’s now significantly more deadly to be homeless. Why are so many people dying?,” CalMatters, Mar. 01, 2024. [Online]. Available: https://calmatters.org/housing/homelessness/2024/02/homeless-mortality-report/\n[8] Black Demographics, “Black population by state - BlackDemographics.com,” BlackDemographics.com, Feb. 08, 2024. https://blackdemographics.com/population/black-state-population/\n[9] “Motor-Vehicle deaths by State - Injury facts,” Injury Facts, Apr. 10, 2024. https://injuryfacts.nsc.org/state-data/motor-vehicle-deaths-by-state/\n[10] “Fatality Facts 2021: State by state,” IIHS-HLDI Crash Testing and Highway Safety. https://www.iihs.org/topics/fatality-statistics/detail/state-by-state\n‌"
  }
]