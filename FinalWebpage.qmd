---
title: "FINAL PROJECT CODE"
format: html
editor: visual
---

```{r}
packages <- c( "randomForest","tree","dplyr", "tidyverse", "plotly", "psych", "ISLR", "leaps", "reshape2","readr")
for (package in packages) {
  if (!(package %in% installed.packages())) {
    install.packages(package, dependencies = TRUE)
  }
}
# Load libraries
suppressMessages({library(dplyr)
library(tidyverse)
library(plotly)
library(psych)
library(ISLR)
library(leaps)
library(reshape2)
library(readr)
library(tree)
library(randomForest)
library(caret)})
```


```{r}
url <- "https://raw.githubusercontent.com/KyleWandel/STAT-515-Final-Project/main/breast-cancer-wisconsin.csv"
df <- read.table(url, header = TRUE, sep = ",")
str(df)
```

To make the dataset ready for analysis we removed the ID column, checked and removed all rows with missing data changed he response variable values to malignant (4) = 1 and benign (2) = 0.

After cleaning the dataset, we looked at a summary statistics for each variable. For our sample there are 444 records that are identified as not being malignant (=0) and 239 records that are identified as being malignant (=1).

```{r}
# remove ID column 
df <- subset(df, select = -id) 
# Change column type
df$barenuclei <- as.integer(df$barenuclei) 
# Look for missing values
colSums(is.na(df)) 
# omit missing values
df_clean <- na.omit(df) 
str(df_clean) 
# Change response variable to 1 and 0
df_clean$benormal <- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal)) 
summary(df_clean) 
table(df_clean$benormal)
```

We next wanted to identify if there were any patterns amongst the predictor variables in the dataset. First we looked at the correlations, histrograms and scatterplots of the variables using the pairs.panel() function.

```{r}
pairs.panels(df_clean)
```
Principal Component Analysis

We first took a look at the mean and variances of the variables in the dataset to see if the variables should be scaled or not. Below are the means an variances of the variables:
```{r}
PCA_df <- df_clean[, -ncol(df_clean)]
states=row.names(PCA_df)
apply(PCA_df, 2, mean)
apply(PCA_df, 2, var)
apply(PCA_df, 2, sd)
# There is difference in the mean and variance, so we do should scale/standardize the variables.
```
After running a PCA analysis found that most of the variables are grouped indicating that there are similar observations based on the variable values. There are not too many outliers to indicate any unusual observations.

```{r}
# Calculate the principal components
pr.out=prcomp(PCA_df, scale=TRUE)
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot(pr.out, scale=0, main = "Biplot of PCA Results", cex =0.7)
```

The following graph is the scree plot for the PCA which is used to provide a simple yet effective way to see balance and the trade-off between retaining information and reducing dimensionality in your data.

```{r}
# Scree plot
(pr.var=pr.out$sdev^2) #variance of each PC
pve=pr.var/sum(pr.var)
pve
par(mfrow =c(1,2))
plot(pve, main = "Scree Plot for Variance Explained",
     xlab="Principal Component", 
     ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
```

The following graph shows cumulative proportion of variance that each principal components adds.

```{r}
plot(cumsum(pve), main = "Scree Plot for Cumulative Variance Explained",
     xlab="Principal Component",
     ylab="Cumulative Proportion of Variance Explained", 
     ylim=c(0,1),type='b')
```

Linear Regression

For the first model we used the cleaned dataset and all of the variables.

```{r}
model_1 <- glm(benormal ~ ., data = df_clean, family = binomial) 
summary(model_1) 
par(mfrow = c(2, 2))
plot(model_1)
```

Next, we wanted to create a new model after logging our variables.

```{r}
variables_to_log <- c("mitoses", "normalnucleoli", "blandchromatin", "epithelial", "margadhesion", "uniformcellshape", "uniformcellsize","clumpthickness") 
df_log <- df_clean 
df_log[variables_to_log] <- lapply(df_log[variables_to_log], log) 
model_2 <- glm(benormal ~ ., data = df_log, family = binomial) 
summary(model_2) 
par(mfrow = c(2, 2))
plot(model_2)
```

Based on the AIC of these two models, the non-logged model performed better. Now lets try and simplify the model.

```{r}
model_3 <- glm(benormal ~ clumpthickness + margadhesion + barenuclei + blandchromatin, data = df_clean, family = binomial) 
summary(model_3) 
model_3 
anova(model_1, model_3, test = "Chisq") 
```

Using model_1 as the final model, lets see how accurate it is for prediction.

```{r}
glm.probs=predict(model_1,type="response")
glm.probs[1:10]
glm.pred=rep(0,nrow(df_clean))
glm.pred[glm.probs>.5]=1
glm.pred=as.factor(glm.pred)
df_clean$benormal=as.factor(df_clean$benormal)
cm = table(glm.pred,df_clean$benormal)
print(cm)
```

Decision Tree and Random Forest Modeling

First, we looked at a decision tree model to determine the best spilt for node splitting. We did this by splitting the data into two sets, training and testing to train the model and then test its accuracy.

```{r}
df_clean$benormal=as.integer(df_clean$benormal)
set.seed(2) 
train = sample(1:nrow(df_clean), nrow(df_clean)/2) 
tree.df_clean=tree(benormal~.,df_clean,subset=train) 
cv.df_clean=cv.tree(tree.df_clean) 
plot(cv.df_clean$size,cv.df_clean$dev,type='b')
```

Based on these results, it is best to include 6 variables in each split. Knowing this, we created a random forest model at the desired variable split.

```{r}
df_clean <- na.omit(df) 
df_clean$benormal <- ifelse(df_clean$benormal == 4, 1, ifelse(df_clean$benormal == 2, 0, df_clean$benormal))
cancer_rf=randomForest(benormal~.,data=df_clean,subset=train,mtry=6,importance=TRUE) 
yhat.rf = predict(cancer_rf,newdata=df_clean[-train,]) 
df_clean.test=df_clean[-train,"benormal"] 
mean((yhat.rf-df_clean.test)^2) #test set MSE 
cancer_rf 
plot(cancer_rf) 
varImpPlot(cancer_rf) 
```

Looking at the confusion matrix:

```{r}
glm.probs=predict(cancer_rf,df_clean,type="response")
glm.probs[1:10]
glm.pred=rep(0,nrow(df_clean))
glm.pred[glm.probs>.5]=1
glm.pred=as.factor(glm.pred)
df_clean$benormal=as.factor(df_clean$benormal)
confusionMatrix(glm.pred,df_clean$benormal)
```

The percent chance the model falsely predicted cancer when not was 6/444 (1.4%) and the chance the model falsely predicted not having cancer when there was 9/239 (3.7%).
